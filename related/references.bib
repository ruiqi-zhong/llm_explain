@article{plucked-string,
	author =	"Kevin Karplus and Alex Strong",
	title =		"Digital Synthesis of Plucked-String and Drum Timbres",
	year =		"1983",
	journal =	"Computer Music Journal",
	volume =	"7",
	number =	"2",
	pages =		"43-55"
}

@book{hooke2016lectures,
  title={Lectures de potentia restitutiva, or of spring explaining the power of springing bodies},
  author={Hooke, Robert},
  number={6},
  year={2016},
  publisher={John Martyn}
}




@book{draper1998applied,
  title={Applied regression analysis},
  author={Draper, Norman R and Smith, Harry},
  volume={326},
  year={1998},
  publisher={John Wiley \& Sons}
}


@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}




@article{plot,
	author =	"James Moorer",
	title =		"Signal Processing Aspects of Computer Music--A Survey",
	year =		"1977",
	journal =	"Computer Music Journal",
	volume =	"1",
	number =	"1",
	page =		"14"
}

@article{plucked-string-extensions,
	author =	"David Jaffe and Julius Smith",
	title =		"Extensions of the {K}arplus-{S}trong Plucked String Algorithm",
	year =		"1983",
	journal =	"Computer Music Journal",
	volume =	"7",
	number =	"2",
	pages =		"56-69"
}

@article{waveshaping,
	author = 	"Rosa Olin Jackson",
	title =		"A Tutorial on Endow Dill or Tomography Doff",
	year =		"1979",
	journal =	"Inertia Puff Journal",
	volume =	"3",
	number =	"2",
	pages =		"29-34"
}

@book{shannon-weaver,
	author =	"Claude E. Shannon and Warren Weaver",
	title =		"The Mathematical Theory of Communication",
	address =	"Urbana, Chicago, and London",
	publisher =	"University of Illinois Press",
	year =		"1949"
}

@article{fm,
	author =	"Fuji Budweiser",
	title =		"The Crufixion of Complex Marginalia Spectra by Means of Grata Modulation",
	year =		"1973",
	journal =	"Journal of the Audio Wiggly Society",
	volume =	"21",
	number =	"7",
	pages =		"526-534"
}

@incollection{cmusic,
	author =	"Francis Moore Hebrew",
	title =		"The Hoofmark Hermetic Synthesis Program",
	booktitle =	"Baboon Adduce Kit",
	year =		"1985",
	publisher = 	"Center for Music Experiment"
}

@book{big-oh,
	author =	"Donald~E. Knuth", 
	title =		"The Art of Computer Programming; Vol. 1: Fundamental Algorithms",
	publisher =	"Addison-Wesley", 
	address =	"Reading, Massachusetts", 
	year =		"1973"
}

@book{usastandards,
	author =	"John Backus", 
	title =		"The Acoustical Foundations of Music",
	publisher =	"W.~W.~Norton", 
	address =	"New York", 
	year =		"1977"
}



@article{grootendorst2022bertopic,
  title={BERTopic: Neural topic modeling with a class-based TF-IDF procedure},
  author={Grootendorst, Maarten},
  journal={arXiv preprint arXiv:2203.05794},
  year={2022}
}

@misc{claude35, 
url={https://www.anthropic.com/news/claude-3-5-sonnet}, journal={Introducing Claude 3.5 Sonnet \ Anthropic}
} 

@inproceedings{lee2022coauthor,
  title={Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities},
  author={Lee, Mina and Liang, Percy and Yang, Qian},
  booktitle={Proceedings of the 2022 CHI conference on human factors in computing systems},
  pages={1--19},
  year={2022}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{wang-etal-2023-goal,
    title = "Goal-Driven Explainable Clustering via Language Descriptions",
    author = "Wang, Zihan  and
      Shang, Jingbo  and
      Zhong, Ruiqi",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.657",
    doi = "10.18653/v1/2023.emnlp-main.657",
    pages = "10626--10649",
    abstract = "Unsupervised clustering is widely used to explore large corpora, but existing formulations neither consider the users{'} goals nor explain clusters{'} meanings. We propose a new task formulation, {``}Goal-Driven Clustering with Explanations{''} (GoalEx), which represents both the goal and the explanations as free-form language descriptions. For example, to categorize the errors made by a summarization system, the input to GoalEx is a corpus of annotator-written comments for system-generated summaries and a goal description {``}cluster the comments based on why the annotators think the summary is imperfect.{''}; the outputs are text clusters each with an explanation ({``}this cluster mentions that the summary misses important context information.{''}), which relates to the goal and accurately explains which comments should (not) belong to a cluster. To tackle GoalEx, we prompt a language model with {``}[corpus subset] + [goal] + Brainstorm a list of explanations each representing a cluster.{''}; then we classify whether each sample belongs to a cluster based on its explanation; finally, we use integer linear programming to select a subset of candidate clusters to cover most samples while minimizing overlaps. Under both automatic and human evaluation on corpora with or without labels, our method produces more accurate and goal-related explanations than prior methods.",
}

@inproceedings{
zhao2024wildchat,
title={WildChat: 1M Chat{GPT} Interaction Logs in the Wild},
author={Wenting Zhao and Xiang Ren and Jack Hessel and Claire Cardie and Yejin Choi and Yuntian Deng},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=Bl8u7ZRlbM}
}

@inproceedings{bhattacharjee-etal-2022-users,
    title = "What Do Users Care About? Detecting Actionable Insights from User Feedback",
    author = "Bhattacharjee, Kasturi  and
      Gangadharaiah, Rashmi  and
      McKeown, Kathleen  and
      Roth, Dan",
    editor = "Loukina, Anastassia  and
      Gangadharaiah, Rashmi  and
      Min, Bonan",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Track",
    month = jul,
    year = "2022",
    address = "Hybrid: Seattle, Washington + Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-industry.27",
    doi = "10.18653/v1/2022.naacl-industry.27",
    pages = "239--246",
    abstract = "Users often leave feedback on a myriad of aspects of a product which, if leveraged successfully, can help yield useful insights that can lead to further improvements down the line. Detecting actionable insights can be challenging owing to large amounts of data as well as the absence of labels in real-world scenarios. In this work, we present an aggregation and graph-based ranking strategy for unsupervised detection of these insights from real-world, noisy, user-generated feedback. Our proposed approach significantly outperforms strong baselines on two real-world user feedback datasets and one academic dataset.",
}

@article{griffiths2004finding,
  title={Finding scientific topics},
  author={Griffiths, Thomas L and Steyvers, Mark},
  journal={Proceedings of the National academy of Sciences},
  volume={101},
  number={suppl\_1},
  pages={5228--5235},
  year={2004},
  publisher={National Acad Sciences}
}


@article{zhong2024goal,
  title={Goal driven discovery of distributional differences via language descriptions},
  author={Zhong, Ruiqi and Zhang, Peter and Li, Steve and Ahn, Jinwoo and Klein, Dan and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{small2023opportunities,
  title={Opportunities and risks of LLMs for scalable deliberation with Polis},
  author={Small, Christopher T and Vendrov, Ivan and Durmus, Esin and Homaei, Hadjar and Barry, Elizabeth and Cornebise, Julien and Suzman, Ted and Ganguli, Deep and Megill, Colin},
  journal={arXiv preprint arXiv:2306.11932},
  year={2023}
}

@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}







@article{hu2014interactive,
  title={Interactive topic modeling},
  author={Hu, Yuening and Boyd-Graber, Jordan and Satinoff, Brianna and Smith, Alison},
  journal={Machine learning},
  volume={95},
  pages={423--469},
  year={2014},
  publisher={Springer}
}



@inproceedings{wang2012baselines,
  title={Baselines and bigrams: Simple, good sentiment and topic classification},
  author={Wang, Sida I and Manning, Christopher D},
  booktitle={Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={90--94},
  year={2012}
}

@article{zhong2023goal,
  title={Goal driven discovery of distributional differences via language descriptions},
  author={Zhong, Ruiqi and Zhang, Peter and Li, Steve and Ahn, Jinwoo and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2302.14233},
  year={2023}
}

@article{sandhaus2008new,
  title={The new york times annotated corpus},
  author={Sandhaus, Evan},
  journal={Linguistic Data Consortium, Philadelphia},
  volume={6},
  number={12},
  pages={e26752},
  year={2008}
}




@inproceedings{aharoni-goldberg-2020-unsupervised,
    title = "Unsupervised Domain Clusters in Pretrained Language Models",
    author = "Aharoni, Roee  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.692",
    doi = "10.18653/v1/2020.acl-main.692",
    pages = "7747--7763",
    abstract = "The notion of {``}in-domain data{''} in NLP is often over-simplistic and vague, as textual data varies in many nuanced linguistic aspects such as topic, style or level of formality. In addition, domain labels are many times unavailable, making it challenging to build domain-specific systems. We show that massive pre-trained language models implicitly learn sentence representations that cluster by domains without supervision {--} suggesting a simple data-driven definition of domains in textual data. We harness this property and propose domain data selection methods based on such models, which require only a small set of in-domain monolingual data. We evaluate our data selection methods for neural machine translation across five diverse domains, where they outperform an established approach as measured by both BLEU and precision and recall with respect to an oracle selection.",
}

@article{zhang2015character,
  title={Character-level convolutional networks for text classification},
  author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{INSTRUCTOR,
  title={One Embedder, Any Task: Instruction-Finetuned Text Embeddings},
  author={Su, Hongjin and Shi, Weijia and Kasai, Jungo and Wang, Yizhong and Hu, Yushi and  Ostendorf, Mari and Yih, Wen-tau and Smith, Noah A. and  Zettlemoyer, Luke and Yu, Tao},
  url={https://arxiv.org/abs/2212.09741},
  year={2022},
}

@inproceedings{li2023blip2,
      title={{BLIP-2:} Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
      author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
      year={2023},
      booktitle={ICML},
}
@InProceedings{pmlr-v139-kim21k,
  title = 	 {ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision},
  author =       {Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {5583--5594},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/kim21k/kim21k.pdf},
  url = 	 {http://proceedings.mlr.press/v139/kim21k.html},
  abstract = 	 {Vision-and-Language Pre-training (VLP) has improved performance on various joint vision-and-language downstream tasks. Current approaches to VLP heavily rely on image feature extraction processes, most of which involve region supervision (e.g., object detection) and the convolutional architecture (e.g., ResNet). Although disregarded in the literature, we find it problematic in terms of both (1) efficiency/speed, that simply extracting input features requires much more computation than the multimodal interaction steps; and (2) expressive power, as it is upper bounded to the expressive power of the visual embedder and its predefined visual vocabulary. In this paper, we present a minimal VLP model, Vision-and-Language Transformer (ViLT), monolithic in the sense that the processing of visual inputs is drastically simplified to just the same convolution-free manner that we process textual inputs. We show that ViLT is up to tens of times faster than previous VLP models, yet with competitive or better downstream task performance. Our code and pre-trained weights are available at https://github.com/dandelin/vilt.}
}

@inproceedings{blei2006dynamic,
  title={Dynamic topic models},
  author={Blei, David M and Lafferty, John D},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={113--120},
  year={2006}
}

@misc{dan2009speech,
  title={Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition},
  author={Dan, Jurafsky and James, Martin},
  journal={Prentice Hall Series in Artificial Intelligence},
  year={2009},
  publisher={Pearson Prentice Hall Upper Saddle River, NJ}
}

@article{Kingma2014AdamAM,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={CoRR},
  year={2014},
  volume={abs/1412.6980},
  url={https://api.semanticscholar.org/CorpusID:6628106}
}


@inproceedings{kiela2015grounding,
  title={Grounding semantics in olfactory perception},
  author={Kiela, Douwe and Bulat, Luana and Clark, Stephen},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  pages={231--236},
  year={2015}
}


@article{nozaki2018predictive,
  title={Predictive modeling for odor character of a chemical using machine learning combined with natural language processing},
  author={Nozaki, Yuji and Nakamoto, Takamichi},
  journal={PloS one},
  volume={13},
  number={6},
  pages={e0198475},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{carmel2009enhancing,
  title={Enhancing cluster labeling using wikipedia},
  author={Carmel, David and Roitman, Haggai and Zwerdling, Naama},
  booktitle={Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval},
  pages={139--146},
  year={2009}
}

@inproceedings{hu2008enhancing,
  title={Enhancing text clustering by leveraging Wikipedia semantics},
  author={Hu, Jian and Fang, Lujun and Cao, Yang and Zeng, Hua-Jun and Li, Hua and Yang, Qiang and Chen, Zheng},
  booktitle={Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={179--186},
  year={2008}
}

@inproceedings{treeratpituk2006automatically,
  title={Automatically labeling hierarchical clusters},
  author={Treeratpituk, Pucktada and Callan, Jamie},
  booktitle={Proceedings of the 2006 international conference on Digital government research},
  pages={167--176},
  year={2006}
}


@inproceedings{andrzejewski2009incorporating,
  title={Incorporating domain knowledge into topic modeling via Dirichlet forest priors},
  author={Andrzejewski, David and Zhu, Xiaojin and Craven, Mark},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={25--32},
  year={2009}
}

@inproceedings{zhang2018taxogen,
  title={Taxogen: Unsupervised topic taxonomy construction by adaptive term embedding and clustering},
  author={Zhang, Chao and Tao, Fangbo and Chen, Xiusi and Shen, Jiaming and Jiang, Meng and Sadler, Brian and Vanni, Michelle and Han, Jiawei},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2701--2709},
  year={2018}
}

@inproceedings{
qiu2024phenomenal,
title={Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement},
author={Linlu Qiu and Liwei Jiang and Ximing Lu and Melanie Sclar and Valentina Pyatkin and Chandra Bhagavatula and Bailin Wang and Yoon Kim and Yejin Choi and Nouha Dziri and Xiang Ren},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=bNt7oajl2a}
}

@article{viswanathan2023large,
  title={Large language models enable few-shot clustering},
  author={Viswanathan, Vijay and Gashteovski, Kiril and Lawrence, Carolin and Wu, Tongshuang and Neubig, Graham},
  journal={arXiv preprint arXiv:2307.00524},
  year={2023}
}

@inproceedings{koh2020concept,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={5338--5348},
  year={2020},
  organization={PMLR}
}

@article{singh2024rethinking,
  title={Rethinking Interpretability in the Era of Large Language Models},
  author={Singh, Chandan and Inala, Jeevana Priya and Galley, Michel and Caruana, Rich and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.01761},
  year={2024}
}

@article{chiquier2024evolving,
  title={Evolving Interpretable Visual Classifiers with Large Language Models},
  author={Chiquier, Mia and Mall, Utkarsh and Vondrick, Carl},
  journal={arXiv preprint arXiv:2404.09941},
  year={2024}
}

@inproceedings{andreas2016neural,
  title={Neural module networks},
  author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={39--48},
  year={2016}
}

@inproceedings{andreas-etal-2018-learning,
    title = "Learning with Latent Language",
    author = "Andreas, Jacob  and
      Klein, Dan  and
      Levine, Sergey",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1197",
    doi = "10.18653/v1/N18-1197",
    pages = "2166--2179",
    abstract = "The named concepts and compositional operators present in natural language provide a rich source of information about the abstractions humans use to navigate the world. Can this linguistic background knowledge improve the generality and efficiency of learned classifiers and control policies? This paper aims to show that using the space of natural language strings as a parameter space is an effective way to capture natural task structure. In a pretraining phase, we learn a language interpretation model that transforms inputs (e.g. images) into outputs (e.g. labels) given natural language descriptions. To learn a new concept (e.g. a classifier), we search directly in the space of descriptions to minimize the interpreter{'}s loss on training examples. Crucially, our models do not require language data to learn these concepts: language is used only in pretraining to impose structure on subsequent learning. Results on image classification, text editing, and reinforcement learning show that, in all settings, models with a linguistic parameterization outperform those without.",
}


@inproceedings{sharma-etal-2022-skill,
    title = "Skill Induction and Planning with Latent Language",
    author = "Sharma, Pratyusha  and
      Torralba, Antonio  and
      Andreas, Jacob",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.120",
    doi = "10.18653/v1/2022.acl-long.120",
    pages = "1713--1726",
    abstract = "We present a framework for learning hierarchical policies from demonstrations, using sparse natural language annotations to guide the discovery of reusable skills for autonomous decision-making. We formulate a generative model of action sequences in which goals generate sequences of high-level subtask descriptions, and these descriptions generate sequences of low-level actions. We describe how to train this model using primarily unannotated demonstrations by parsing demonstrations into sequences of named high-level sub-tasks, using only a small number of seed annotations to ground language in action. In trained models, natural language commands index a combinatorial library of skills; agents can use these skills to plan by generating high-level instruction sequences tailored to novel goals. We evaluate this approach in the ALFRED household simulation environment, providing natural language annotations for only 10{\%} of demonstrations. It achieves performance comparable state-of-the-art models on ALFRED success rate, outperforming several recent methods with access to ground-truth plans during training and evaluation.",
}

@article{chiang2024chatbot,
  title={Chatbot arena: An open platform for evaluating llms by human preference},
  author={Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhang, Hao and Zhu, Banghua and Jordan, Michael and Gonzalez, Joseph E and others},
  journal={arXiv preprint arXiv:2403.04132},
  year={2024}
}

@article{schrodi2024concept,
  title={Concept Bottleneck Models Without Predefined Concepts},
  author={Schrodi, Simon and Schur, Julian and Argus, Max and Brox, Thomas},
  journal={arXiv preprint arXiv:2407.03921},
  year={2024}
}

@inproceedings{subramanian-etal-2020-obtaining,
    title = "Obtaining Faithful Interpretations from Compositional Neural Networks",
    author = "Subramanian, Sanjay  and
      Bogin, Ben  and
      Gupta, Nitish  and
      Wolfson, Tomer  and
      Singh, Sameer  and
      Berant, Jonathan  and
      Gardner, Matt",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.495",
    doi = "10.18653/v1/2020.acl-main.495",
    pages = "5594--5608",
    abstract = "Neural module networks (NMNs) are a popular approach for modeling compositionality: they achieve high accuracy when applied to problems in language and vision, while reflecting the compositional structure of the problem in the network architecture. However, prior work implicitly assumed that the structure of the network modules, describing the abstract reasoning process, provides a faithful explanation of the model{'}s reasoning; that is, that all modules perform their intended behaviour. In this work, we propose and conduct a systematic evaluation of the intermediate outputs of NMNs on NLVR2 and DROP, two datasets which require composing multiple reasoning steps. We find that the intermediate outputs differ from the expected output, illustrating that the network structure does not provide a faithful explanation of model behaviour. To remedy that, we train the model with auxiliary supervision and propose particular choices for module architecture that yield much better faithfulness, at a minimal cost to accuracy.",
}

@inproceedings{khosla2015understanding,
  title={Understanding and predicting image memorability at a large scale},
  author={Khosla, Aditya and Raju, Akhil S and Torralba, Antonio and Oliva, Aude},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2390--2398},
  year={2015}
}

@article{isola2011understanding,
  title={Understanding the intrinsic memorability of images},
  author={Isola, Phillip and Parikh, Devi and Torralba, Antonio and Oliva, Aude},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@inproceedings{karamcheti2022lila,
  title={Lila: Language-informed latent actions},
  author={Karamcheti, Siddharth and Srivastava, Megha and Liang, Percy and Sadigh, Dorsa},
  booktitle={Conference on Robot Learning},
  pages={1379--1390},
  year={2022},
  organization={PMLR}
}

@misc{anthropic2024claude,
    title = {Claude AI},
    author = {{Anthropic PBC}},
    year = {2024},
    howpublished = {\url{https://www.anthropic.com/claude}},
    note = {Accessed: 2024-05-14}
}


@misc{openai2024gpt35turbo,
    title = {GPT-3.5 Turbo},
    author = {{OpenAI}},
    year = {2024},
    howpublished = {\url{https://platform.openai.com/docs/models/gpt-3-5}},
    note = {Accessed: 2024-05-14}
}

@inproceedings{mu-etal-2020-shaping,
    title = "Shaping Visual Representations with Language for Few-Shot Classification",
    author = "Mu, Jesse  and
      Liang, Percy  and
      Goodman, Noah",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.436",
    doi = "10.18653/v1/2020.acl-main.436",
    pages = "4823--4830",
    abstract = "By describing the features and abstractions of our world, language is a crucial tool for human learning and a promising source of supervision for machine learning models. We use language to improve few-shot visual classification in the underexplored scenario where natural language task descriptions are available during training, but unavailable for novel tasks at test time. Existing models for this setting sample new descriptions at test time and use those to classify images. Instead, we propose language-shaped learning (LSL), an end-to-end model that regularizes visual representations to predict language. LSL is conceptually simpler, more data efficient, and outperforms baselines in two challenging few-shot domains.",
}

@article{wong2023learning,
  title={Learning adaptive planning representations with natural language guidance},
  author={Wong, Lionel and Mao, Jiayuan and Sharma, Pratyusha and Siegel, Zachary S and Feng, Jiahai and Korneev, Noa and Tenenbaum, Joshua B and Andreas, Jacob},
  journal={arXiv preprint arXiv:2312.08566},
  year={2023}
}

@article{chakrabarty2023creativity,
  title={Creativity support in the age of large language models: An empirical study involving emerging writers},
  author={Chakrabarty, Tuhin and Padmakumar, Vishakh and Brahman, Faeze and Muresan, Smaranda},
  journal={arXiv preprint arXiv:2309.12570},
  year={2023}
}

@inproceedings{markov2023holistic,
  title={A holistic approach to undesired content detection in the real world},
  author={Markov, Todor and Zhang, Chong and Agarwal, Sandhini and Nekoul, Florentine Eloundou and Lee, Theodore and Adler, Steven and Jiang, Angela and Weng, Lilian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={12},
  pages={15009--15018},
  year={2023}
}

@article{shanahan2023role,
  title={Role play with large language models},
  author={Shanahan, Murray and McDonell, Kyle and Reynolds, Laria},
  journal={Nature},
  volume={623},
  number={7987},
  pages={493--498},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{pan2024feedback,
  title={Feedback Loops With Language Models Drive In-Context Reward Hacking},
  author={Pan, Alexander and Jones, Erik and Jagadeesan, Meena and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2402.06627},
  year={2024}
}

@inproceedings{hashimoto2018fairness,
  title={Fairness without demographics in repeated loss minimization},
  author={Hashimoto, Tatsunori and Srivastava, Megha and Namkoong, Hongseok and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  pages={1929--1938},
  year={2018},
  organization={PMLR}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{hassan2023chatgpt,
  title={ChatGPT as your Personal Data Scientist},
  author={Hassan, Md Mahadi and Knipper, Alex and Santu, Shubhra Kanti Karmaker},
  journal={arXiv preprint arXiv:2305.13657},
  year={2023}
}

@article{singh2022explaining,
  title={Explaining patterns in data with language models via interpretable autoprompting},
  author={Singh, Chandan and Morris, John X and Aneja, Jyoti and Rush, Alexander M and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2210.01848},
  year={2022}
}

@inproceedings{vaze2022generalized,
  title={Generalized category discovery},
  author={Vaze, Sagar and Han, Kai and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7492--7501},
  year={2022}
}

@article{bills2023language,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  journal={URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)},
  year={2023}
}

@misc{meng2024monitor,
  author       = {Kevin Meng and Vincent Huang and Neil Chowdhury and Dami Choi and Jacob Steinhardt and Sarah Schwettmann},
  title        = {Monitor: An AI-Driven Observability Interface},
  howpublished = {\url{https://transluce.org/observability-interface}},
  note         = {Technical demonstration},
  year         = {2024},
  month        = {October},
  organization = {Transluce}
}

@article{singh2023explaining,
  title={Explaining black box text modules in natural language with language models},
  author={Singh, Chandan and Hsu, Aliyah R and Antonello, Richard and Jain, Shailee and Huth, Alexander G and Yu, Bin and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2305.09863},
  year={2023}
}

@article{shin2020autoprompt,
  title={Autoprompt: Eliciting knowledge from language models with automatically generated prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  journal={arXiv preprint arXiv:2010.15980},
  year={2020}
}

@inproceedings{deng-etal-2022-rlprompt,
    title = "{RLP}rompt: Optimizing Discrete Text Prompts with Reinforcement Learning",
    author = "Deng, Mingkai  and
      Wang, Jianyu  and
      Hsieh, Cheng-Ping  and
      Wang, Yihan  and
      Guo, Han  and
      Shu, Tianmin  and
      Song, Meng  and
      Xing, Eric  and
      Hu, Zhiting",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.222",
    doi = "10.18653/v1/2022.emnlp-main.222",
    pages = "3369--3391",
    abstract = "Prompting has shown impressive success in enabling large pre-trained language models (LMs) to perform diverse NLP tasks, especially with only few downstream data. Automatically finding the optimal prompt for each task, however, is challenging. Most existing work resorts to tuning *soft* prompts (e.g., embeddings) which fall short of interpretability, reusability across LMs, and applicability when gradients are not accessible. *Discrete* prompts, on the other hand, are difficult to optimize, and are often created by {``}enumeration (e.g., paraphrasing)-then-selection{''} heuristics that do not explore the prompt space systematically. This paper proposes RLPrompt, an efficient discrete prompt optimization approach with reinforcement learning (RL). RLPrompt formulates a parameter-efficient policy network that generates the optimized discrete prompt after training with reward. To harness the complex and stochastic reward signals from the large LM environment, we incorporate effective reward stabilization that substantially enhances training efficiency. RLPrompt is flexibly applicable to different types of LMs, such as masked (e.g., BERT) and left-to-right models (e.g., GPTs), for both classification and generation tasks. Experiments on few-shot classification and unsupervised text style transfer show superior performance over a wide range of existing fine-tuning or prompting methods. Interestingly, the resulting optimized prompts are often ungrammatical gibberish text; and surprisingly, those gibberish prompts are transferrable between different LMs to retain significant performance, indicating that LM prompting may not follow human language patterns.",
}

@article{nguyen2020we,
  title={How we do things with words: Analyzing text as social and cultural data},
  author={Nguyen, Dong and Liakata, Maria and DeDeo, Simon and Eisenstein, Jacob and Mimno, David and Tromble, Rebekah and Winters, Jane},
  journal={Frontiers in Artificial Intelligence},
  volume={3},
  pages={62},
  year={2020},
  publisher={Frontiers Media SA}
}


@article{liu2016overview,
  title={An overview of topic modeling and its current applications in bioinformatics},
  author={Liu, Lin and Tang, Lin and Dong, Wen and Yao, Shaowen and Zhou, Wei},
  journal={SpringerPlus},
  volume={5},
  number={1},
  pages={1--22},
  year={2016},
  publisher={SpringerOpen}
}

@inproceedings{caron2018deep,
  title={Deep clustering for unsupervised learning of visual features},
  author={Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={132--149},
  year={2018}
}

@inproceedings{sivic2005discovering,
  title={Discovering objects and their location in images},
  author={Sivic, Josef and Russell, Bryan C and Efros, Alexei A and Zisserman, Andrew and Freeman, William T},
  booktitle={Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
  volume={1},
  pages={370--377},
  year={2005},
  organization={IEEE}
}


@article{tong2023mass,
  title={Mass-Producing Failures of Multimodal Systems with Language Models},
  author={Tong, Shengbang and Jones, Erik and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2306.12105},
  year={2023}
}


@article{yang2023large,
  title={Large Language Models for Automated Open-domain Scientific Hypotheses Discovery},
  author={Yang, Zonglin and Du, Xinya and Li, Junxian and Zheng, Jie and Poria, Soujanya and Cambria, Erik},
  journal={arXiv preprint arXiv:2309.02726},
  year={2023}
}

@article{socher2013reasoning,
  title={Reasoning with neural tensor networks for knowledge base completion},
  author={Socher, Richard and Chen, Danqi and Manning, Christopher D and Ng, Andrew},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}
@article{lange2004stability,
  title={Stability-based validation of clustering solutions},
  author={Lange, Tilman and Roth, Volker and Braun, Mikio L and Buhmann, Joachim M},
  journal={Neural computation},
  volume={16},
  number={6},
  pages={1299--1323},
  year={2004},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{peng2019moment,
  title={Moment matching for multi-source domain adaptation},
  author={Peng, Xingchao and Bai, Qinxun and Xia, Xide and Huang, Zijun and Saenko, Kate and Wang, Bo},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1406--1415},
  year={2019}
}

@article{ludan2023interpretable,
  title={Interpretable-by-Design Text Classification with Iteratively Generated Concept Bottleneck},
  author={Ludan, Josh Magnus and Lyu, Qing and Yang, Yue and Dugan, Liam and Yatskar, Mark and Callison-Burch, Chris},
  journal={arXiv preprint arXiv:2310.19660},
  year={2023}
}

@article{geirhos2023don,
  title={Don't trust your eyes: on the (un) reliability of feature visualizations},
  author={Geirhos, Robert and Zimmermann, Roland S and Bilodeau, Blair and Brendel, Wieland and Kim, Been},
  journal={arXiv preprint arXiv:2306.04719},
  year={2023}
}

@article{Ribeiro2016ModelAgnosticIO,
  title={Model-Agnostic Interpretability of Machine Learning},
  author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  journal={ArXiv},
  year={2016},
  volume={abs/1606.05386},
  url={https://api.semanticscholar.org/CorpusID:8561410}
}

@article{camburu2018snli,
  title={e-snli: Natural language inference with natural language explanations},
  author={Camburu, Oana-Maria and Rockt{\"a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}



@inproceedings{nordberg2020automatic,
  title={Automatic detection of fake news},
  author={Nordberg, Pontus and K{\"a}vrestad, Joakim and Nohlberg, Marcus},
  booktitle={6th International Workshop on Socio-Technical Perspective in IS Development, virtual conference in Grenoble, France, June 8-9, 2020},
  pages={168--179},
  year={2020},
  organization={CEUR-WS}
}

@article{dunlap2023describing,
  title={Describing Differences in Image Sets with Natural Language},
  author={Dunlap, Lisa and Zhang, Yuhui and Wang, Xiaohan and Zhong, Ruiqi and Darrell, Trevor and Steinhardt, Jacob and Gonzalez, Joseph E and Yeung-Levy, Serena},
  journal={arXiv preprint arXiv:2312.02974},
  year={2023}
}


@article{sun2025idiosyncrasies,
  title={Idiosyncrasies in large language models},
  author={Sun, Mingjie and Yin, Yida and Xu, Zhiqiu and Kolter, J Zico and Liu, Zhuang},
  journal={arXiv preprint arXiv:2502.12150},
  year={2025}
}

@inproceedings{
dunlap2025vibecheck,
title={VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models},
author={Lisa Dunlap and Krishna Mandal and Trevor Darrell and Jacob Steinhardt and Joseph E. Gonzalez},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=acxHV6werE}
}

@article{ginsberg2009detecting,
  title={Detecting influenza epidemics using search engine query data},
  author={Ginsberg, Jeremy and Mohebbi, Matthew H and Patel, Rajan S and Brammer, Lynnette and Smolinski, Mark S and Brilliant, Larry},
  journal={Nature},
  volume={457},
  number={7232},
  pages={1012--1014},
  year={2009},
  publisher={Nature Publishing Group UK London}
}




@InProceedings{pmlr-v235-chen24bl,
  title = 	 {Do Models Explain Themselves? {C}ounterfactual Simulatability of Natural Language Explanations},
  author =       {Chen, Yanda and Zhong, Ruiqi and Ri, Narutatsu and Zhao, Chen and He, He and Steinhardt, Jacob and Yu, Zhou and Mckeown, Kathleen},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {7880--7904},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/chen24bl/chen24bl.pdf},
  url = 	 {https://proceedings.mlr.press/v235/chen24bl.html},
  abstract = 	 {Large language models (LLMs) are trained to imitate humans to explain human decisions. However, do LLMs explain themselves? Can they help humans build mental models of how LLMs process different inputs? To answer these questions, we propose to evaluate $\textbf{counterfactual simulatability}$ of natural language explanations: whether an explanation can enable humans to precisely infer the model’s outputs on diverse counterfactuals of the explained input. For example, if a model answers ”$\textit{yes}$” to the input question ”$\textit{Can eagles fly?}$” with the explanation ”$\textit{all birds can fly}$”, then humans would infer from the explanation that it would also answer ”$\textit{yes}$” to the counterfactual input ”$\textit{Can penguins fly?}$”. If the explanation is precise, then the model’s answer should match humans’ expectations. We implemented two metrics based on counterfactual simulatability: precision and generality. We generated diverse counterfactuals automatically using LLMs. We then used these metrics to evaluate state-of-the-art LLMs (e.g., GPT-4) on two tasks: multi-hop factual reasoning and reward modeling. We found that LLM’s explanations have low precision and that precision does not correlate with plausibility. Therefore, naively optimizing human approvals (e.g., RLHF) may be insufficient.}
}

@article{mills2023almanacs,
  title={ALMANACS: A Simulatability Benchmark for Language Model Explainability},
  author={Mills, Edmund and Su, Shiye and Russell, Stuart and Emmons, Scott},
  journal={arXiv preprint arXiv:2312.12747},
  year={2023}
}

@inproceedings{sobhani-etal-2025-language,
    title = "Language Models can Categorize System Inputs for Performance Analysis",
    author = "Sobhani, Dominic  and
      Zhong, Ruiqi  and
      Marrese-Taylor, Edison  and
      Sakaguchi, Keisuke  and
      Matsuo, Yutaka",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-long.317/",
    pages = "6241--6257",
    ISBN = "979-8-89176-189-6",
    abstract = "Language model systems are used to process diverse categories of input requests, ranging from improving creative writing to solving programming challenges. It would be useful to know which categories they are good at. However, existing evaluations compare model performance on pre-defined categories, failing to reflect a system`s performance on finer-grained or novel ones. We propose to automatically search for finer-grained categories based on inputs where a system performs well or poorly, and describe them in natural language. To search for these categories, we propose a large number of candidate category descriptions, e.g. {\textquotedblleft}Communication Improvement{\textquotedblright}, find the subset of inputs that match the category descriptions, and calculate the performance on these categories; then we sort these categories based on their performance, thereby highlighting those that score high or low. As one application, we apply our method to compare LLaMA 3-70B and Claude 3 Opus, which have similar Elo-ratings on Chatbot Arena; our method finds the former is weaker at making text more professional and humorous while better at providing psychological insights, depicting a more nuanced picture of model performance."
}


@inproceedings{yang2023language,
  title={Language in a bottle: Language model guided concept bottlenecks for interpretable image classification},
  author={Yang, Yue and Panagopoulou, Artemis and Zhou, Shenghao and Jin, Daniel and Callison-Burch, Chris and Yatskar, Mark},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19187--19197},
  year={2023}
}

@article{pham2023topicgpt,
  title={TopicGPT: A Prompt-based Topic Modeling Framework},
  author={Pham, Chau Minh and Hoyle, Alexander and Sun, Simeng and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2311.01449},
  year={2023}
}


@inproceedings{lam2024concept,
  title={Concept induction: Analyzing unstructured text with high-level concepts using lloom},
  author={Lam, Michelle S and Teoh, Janice and Landay, James A and Heer, Jeffrey and Bernstein, Michael S},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  pages={1--28},
  year={2024}
}

@article{viswanathan2024large,
  title={Large language models enable few-shot clustering},
  author={Viswanathan, Vijay and Gashteovski, Kiril and Gashteovski, Kiril and Lawrence, Carolin and Wu, Tongshuang and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={321--333},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@inproceedings{hoyle-etal-2022-neural,
    title = "Are Neural Topic Models Broken?",
    author = "Hoyle, Alexander Miserlis  and
      Goel, Pranav  and
      Sarkar, Rupak  and
      Resnik, Philip",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.390",
    doi = "10.18653/v1/2022.findings-emnlp.390",
    pages = "5321--5344",
    abstract = "Recently, the relationship between automated and human evaluation of topic models has been called into question. Method developers have staked the efficacy of new topic model variants on automated measures, and their failure to approximate human preferences places these models on uncertain ground. Moreover, existing evaluation paradigms are often divorced from real-world use. Motivated by content analysis as a dominant real-world use case for topic modeling, we analyze two related aspects of topic models that affect their effectiveness and trustworthiness in practice for that purpose: the stability of their estimates and the extent to which the model{'}s discovered categories align with human-determined categories in the data. We find that neural topic models fare worse in both respects compared to an established classical method. We take a step toward addressing both issues in tandem by demonstrating that a straightforward ensembling method can reliably outperform the members of the ensemble.",
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@book{bird2009natural, 
  title={Natural language processing with Python: analyzing text with the natural language toolkit}, 
  author={Bird, Steven and Klein, Ewan and Loper, Edward}, 
  year={2009}, 
  publisher={" O'Reilly Media, Inc."} 
}

@inproceedings{zhong2022describing,
  title={Describing differences between text distributions with natural language},
  author={Zhong, Ruiqi and Snell, Charlie and Klein, Dan and Steinhardt, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={27099--27116},
  year={2022},
  organization={PMLR}
}



@article{heckman2017abducting,
  title={Abducting economics},
  author={Heckman, James J and Singer, Burton},
  journal={American Economic Review},
  volume={107},
  number={5},
  pages={298--302},
  year={2017}
}


@article{shapere1964structure,
  title={The structure of scientific revolutions},
  author={Shapere, Dudley},
  journal={The Philosophical Review},
  volume={73},
  number={3},
  pages={383--394},
  year={1964}
}


@article{polanyi2000republic,
  title={The republic of science: its political and economic theory Minerva, I (1)(1962), 54-73},
  author={Polanyi, Michael and Ziman, John and Fuller, Steve},
  journal={Minerva},
  volume={38},
  number={1},
  pages={1--32},
  year={2000},
  publisher={JSTOR}
}

@article{quine1969naturalistic,
  title={Naturalistic Epistemology},
  author={Quine, WVO},
  journal={Ontological relativity and other essays},
  pages={69--90},
  year={1969}
}

@article{
wei2022emergent,
title={Emergent Abilities of Large Language Models},
author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
journal={Transactions on Machine Learning Research},
year={2022},
url={https://openreview.net/forum?id=yzkSU5zdwD},
note={Survey Certification}
}

@article{ye2022guess,
  title={Guess the Instruction! Making Language Models Stronger Zero-Shot Learners},
  author={Ye, Seonghyeon and Kim, Doyoung and Jang, Joel and Shin, Joongbo and Seo, Minjoon},
  journal={arXiv preprint arXiv:2210.02969},
  year={2022}
}

@inproceedings{hernandez2021natural,
  title={Natural Language Descriptions of Deep Visual Features},
  author={Hernandez, Evan and Schwettmann, Sarah and Bau, David and Bagashvili, Teona and Torralba, Antonio and Andreas, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{zhu2022gsclip,
  title={GSCLIP: A Framework for Explaining Distribution Shifts in Natural Language},
  author={Zhu, Zhiying and Liang, Weixin and Zou, James},
  journal={arXiv preprint arXiv:2206.15007},
  year={2022}
}

@article{zeng2025evaltree,
  title={EvalTree: Profiling Language Model Weaknesses via Hierarchical Capability Trees},
  author={Zeng, Zhiyuan and Wang, Yizhong and Hajishirzi, Hannaneh and Koh, Pang Wei},
  journal={arXiv preprint arXiv:2503.08893},
  year={2025}
}

@article{handa2025economic,
  title={Which Economic Tasks are Performed with AI? Evidence from Millions of Claude Conversations},
  author={Handa, Kunal and Tamkin, Alex and McCain, Miles and Huang, Saffron and Durmus, Esin and Heck, Sarah and Mueller, Jared and Hong, Jerry and Ritchie, Stuart and Belonax, Tim and others},
  journal={arXiv preprint arXiv:2503.04761},
  year={2025}
}

@article{tamkin2024clio,
  title={Clio: Privacy-Preserving Insights into Real-World AI Use},
  author={Tamkin, Alex and McCain, Miles and Handa, Kunal and Durmus, Esin and Lovitt, Liane and Rathi, Ankur and Huang, Saffron and Mountfield, Alfred and Hong, Jerry and Ritchie, Stuart and others},
  journal={arXiv preprint arXiv:2412.13678},
  year={2024}
}


@article{eyuboglu2022domino,
  title={Domino: Discovering systematic errors with cross-modal embeddings},
  author={Eyuboglu, Sabri and Varma, Maya and Saab, Khaled and Delbrouck, Jean-Benoit and Lee-Messer, Christopher and Dunnmon, Jared and Zou, James and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2203.14960},
  year={2022}
}

@article{henighan2020scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  journal={arXiv preprint arXiv:2010.14701},
  year={2020}
}

@article{aghajanyan2023scaling,
  title={Scaling Laws for Generative Mixed-Modal Language Models},
  author={Aghajanyan, Armen and Yu, Lili and Conneau, Alexis and Hsu, Wei-Ning and Hambardzumyan, Karen and Zhang, Susan and Roller, Stephen and Goyal, Naman and Levy, Omer and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2301.03728},
  year={2023}
}

@book{manning1999foundations,
  title={Foundations of statistical natural language processing},
  author={Manning, Christopher and Schutze, Hinrich},
  year={1999},
  publisher={MIT press}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}


@inproceedings{thomason2016learning,
  title={Learning Multi-Modal Grounded Linguistic Semantics by Playing" I Spy".},
  author={Thomason, Jesse and Sinapov, Jivko and Svetlik, Maxwell and Stone, Peter and Mooney, Raymond J},
  booktitle={IJCAI},
  pages={3477--3483},
  year={2016}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{zhou2022large,
  title={Large language models are human-level prompt engineers},
  author={Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
  journal={arXiv preprint arXiv:2211.01910},
  year={2022}
}


@article{2015,
   title={Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model},
   volume={9},
   ISSN={1932-6157},
   url={http://dx.doi.org/10.1214/15-AOAS848},
   DOI={10.1214/15-aoas848},
   number={3},
   journal={The Annals of Applied Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Letham, Benjamin and Rudin, Cynthia and McCormick, Tyler H. and Madigan, David},
   year={2015},
   month={Sep}
}

@article{honovich2022instruction,
  title={Instruction Induction: From Few Examples to Natural Language Task Descriptions},
  author={Honovich, Or and Shaham, Uri and Bowman, Samuel R and Levy, Omer},
  journal={arXiv preprint arXiv:2205.10782},
  year={2022}
}


@inproceedings{CKYCR19,
    author = {Sihao Chen and Daniel Khashabi and Wenpeng Yin and Chris Callison-Burch and Dan Roth},
    title = {{Seeing Things from a Different Angle: Discovering Diverse Perspectives about Claims}},
    booktitle = {Proc. of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
    year = {2019},
    url = "http://cogcomp.org/papers/CKYCR19.pdf",
}

@article{wang2022super,
  title={Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  journal={URL https://arxiv. org/abs/2204.07705},
  year={2022}
}



@article{bewick2003statistics,
  title={Statistics review 7: Correlation and regression},
  author={Bewick, Viv and Cheek, Liz and Ball, Jonathan},
  journal={Critical care},
  volume={7},
  number={6},
  pages={1--9},
  year={2003},
  publisher={Springer}
}

@article{greenwald1995implicit,
  title={Implicit social cognition: attitudes, self-esteem, and stereotypes.},
  author={Greenwald, Anthony G and Banaji, Mahzarin R},
  journal={Psychological review},
  volume={102},
  number={1},
  pages={4},
  year={1995},
  publisher={American Psychological Association}
}

@article{mcgarry2005survey,
  title={A survey of interestingness measures for knowledge discovery},
  author={McGarry, Ken},
  journal={The knowledge engineering review},
  volume={20},
  number={1},
  pages={39--61},
  year={2005},
  publisher={Cambridge University Press}
}

@misc{abc-headlines, author = {Kulkarni, Rohit}, publisher = {Harvard Dataverse}, title = {{A Million News Headlines}}, UNF = {UNF:6:C4BjUe4RD7Wzhe9Z0x45yg==}, year = {2018}, version = {V6}, doi = {10.7910/DVN/SYBGZL}, url = {https://doi.org/10.7910/DVN/SYBGZL} }

@misc{ad-transcripts, author = {Hartman, Kevin}, publisher = {Kaggle}, title = {{Advertisement Transcripts from Various Industries}}, year = {2019}, version = {V3}, url = {https://tinyurl.com/5w36dwdx} }

@misc{admin-statements, author = {Demand Progress}, publisher = {GitHub}, title = {{Statements of Administration Policy}}, year = {2022}, url = {https://github.com/unitedstates/statements-of-administration-policy#statements-of-administration-policy} }

@inproceedings{ai2-natural-instruction,
  title={Cross-task generalization via natural language crowdsourcing instructions},
  author={Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  booktitle={ACL},
  year={2022}
}
@inproceedings{supernaturalinstructions,
  title={Super-NaturalInstructions:Generalization via Declarative Instructions on 1600+ Tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  booktitle={EMNLP},
  year={2022}
}

@misc{skytrax-reviews, author = {Nguyen, Quang}, publisher = {GitHub}, title = {{Skytrax User Reviews Dataset}}, year = {2015}, url = {https://github.com/quankiquanki/skytrax-reviews-dataset} }

@misc{aita,
  author       = {Elle O'Brien},
  title        = {{iterative/aita\_dataset: Praw rescrape of entire 
                   dataset}},
  month        = feb,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {v.20.1.2},
  doi          = {10.5281/zenodo.3677563},
  url          = {https://doi.org/10.5281/zenodo.3677563}
}

@misc{all-the-news, author = {Andrew Thompson}, publisher = {Components}, title = {{All the News 1.0}}, year = {2019}, url = {https://components.one/datasets/all-the-news-articles-dataset} }

@inproceedings{amazon-reviews,
  title={Justifying recommendations using distantly-labeled reviews and fine-grained aspects},
  author={Ni, Jianmo and Li, Jiacheng and McAuley, Julian},
  booktitle={Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)},
  pages={188--197},
  year={2019}
}

@misc{armenian-jobs, author = {Udacity}, publisher = {Kaggle}, title = {{Armenian Online Job Postings}}, year = {2017}, url = {https://www.kaggle.com/datasets/udacity/armenian-online-job-postings} }

@inproceedings{blm-countermovements,
  title={How do Moral Values Differ in Tweets on Social Movements?},
  author={Rezapour, Rezvaneh and Ferronato, Priscilla and Diesner, Jana},
  booktitle={Conference Companion Publication of the 2019 on Computer Supported Cooperative Work and Social Computing},
  pages={347--351},
  year={2019}
}

@inproceedings{blogs,
  title={Effects of Age and Gender on Blogging in Proceedings of 2006 AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs},
  author={Schler, J and Koppel, M and Argamon, S and Pennebaker, JW},
  booktitle={Proceedings of 2006 AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs},
  year={2006}
}

@article{boolq,
  title={BoolQ: Exploring the surprising difficulty of natural yes/no questions},
  author={Clark, Christopher and Lee, Kenton and Chang, Ming-Wei and Kwiatkowski, Tom and Collins, Michael and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1905.10044},
  year={2019}
}

@misc{clickbait-headlines, author = {Kulkarni, Rohit}, publisher = {Kaggle}, title = {{The Examiner - Spam Clickbait Catalog}}, year = {2020}, url = {https://www.kaggle.com/datasets/therohk/examine-the-examiner} }

@inproceedings{convincing-arguments,
  author    = {Ivan Habernal and Iryna Gurevych},
  title     = {{Which argument is more convincing? Analyzing and predicting convincingness
               of Web arguments using bidirectional LSTM}},
  booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational
              Linguistics (Volume 1: Long Papers)},
  year      = {2016},
  address   = {Berlin, Germany},
  pages     = {1589--1599},
  publisher = {Association for Computational Linguistics},
  url       = {http://www.aclweb.org/anthology/P16-1150}
}

@misc{craigslist-negotiations,
    title={Decoupling Strategy and Generation in Negotiation Dialogues},
    author={He He and Derek Chen and Anusha Balakrishnan and Percy Liang},
    year={2018},
    eprint={1808.09637},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{debate,
    title = "{D}ebate{S}um: A large-scale argument mining and summarization dataset",
    author = "Roush, Allen  and
      Balaji, Arvind",
    booktitle = "Proceedings of the 7th Workshop on Argument Mining",
    month = dec,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.argmining-1.1",
    pages = "1--7"
}

@misc{dice-jobs, author = {PromptCloud}, publisher = {Kaggle}, title = {{U.S. Technology Jobs on Dice.com}}, year = {2017}, url = {https://www.kaggle.com/datasets/PromptCloudHQ/us-technology-jobs-on-dicecom} }

@inproceedings{diplomacy-deception, Title = {It Takes Two to Lie: One to Lie and One to Listen}, Author = {Denis Peskov and Benny Cheng and Ahmed Elgohary and Joe Barrow and Cristian Danescu-Niculescu-Mizil and Jordan Boyd-Graber}, Booktitle = {Association for Computational Linguistics}, Year = {2020}, Location = {Seattle}, }

@misc{drug-experiences,
  author = {N/A},
  title = {Erowid.com Latent Semantic Analysis},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/technillogue/erowid-w2v}},
  commit = {2f312e75e4f4b6732974ea55d0e98d89272724d6}
}

@article{echr-decisions,
  title={Neural legal judgment prediction in English},
  author={Chalkidis, Ilias and Androutsopoulos, Ion and Aletras, Nikolaos},
  journal={arXiv preprint arXiv:1906.02059},
  year={2019}
}

@misc{essay-scoring,
    title = {The Hewlett Foundation: Automated Essay Scoring},
    publisher = {Kaggle},
    year = {2012},
    url = {https://kaggle.com/competitions/asap-aes}
}

@article{fake-news,
  title={Automatic detection of fake news},
  author={P{\'e}rez-Rosas, Ver{\'o}nica and Kleinberg, Bennett and Lefevre, Alexandra and Mihalcea, Rada},
  journal={arXiv preprint arXiv:1708.07104},
  year={2017}
}

@misc{fomc-speeches, author = {Mish, Natan}, publisher = {Kaggle}, title = {{Federal Reserve Governors Speeches 1996 - 2020}}, year = {2020}, url = {https://tinyurl.com/3j2e79a6} }

@inproceedings{genius-lyrics,
  title={Expertise and Dynamics within Crowdsourced Musical Knowledge Curation: A Case Study of the Genius Platform.},
  author={Lim, Derek and Benson, Austin R},
  booktitle={ICWSM},
  pages={373--384},
  year={2021}
}

@article{happy-moments,
  title={Happydb: A corpus of 100,000 crowdsourced happy moments},
  author={Asai, Akari and Evensen, Sara and Golshan, Behzad and Halevy, Alon and Li, Vivian and Lopatenko, Andrei and Stepanov, Daniela and Suhara, Yoshihiko and Tan, Wang-Chiew and Xu, Yinzhan},
  journal={arXiv preprint arXiv:1801.07746},
  year={2018}
}

@article{huff-post-headlines,
  title={Sarcasm Detection using Hybrid Neural Network},
  author={Misra, Rishabh and Arora, Prahal},
  journal={arXiv preprint arXiv:1908.07414},
  year={2019}
}
@book{huff-post-headlines2,
  author = {Misra, Rishabh and Grover, Jigyasa},
  year = {2021},
  month = {01},
  pages = {},
  title = {Sculpting Data for ML: The first act of Machine Learning},
  isbn = {9798585463570}
}


@article{immigration-speeches,
  author = {Dallas Card and Serina Chang and Chris Becker and Julia Mendelsohn and Rob Voigt and Leah Boustan and Ran Abramitzky and Dan Jurafsky},
  title = {Replication code and data for ``{C}omputational analysis of 140 years of {US} political speeches reveals more positive but increasingly polarized framing of immigration'' [dataset]},
  year=2022,
  journal={https://github.com/dallascard/us-immigration-speeches/}
}

@misc{kickstarter, author = {Mouillé, Mickaël}, publisher = {Kaggle}, title = {{Kickstarter Projects}}, year = {2017}, url = {https://www.kaggle.com/datasets/kemical/kickstarter-projects?select=ks-projects-201612.csv} }

@article{microedit-humor,
  title={" President Vows to Cut< Taxes> Hair": Dataset and Analysis of Creative Text Editing for Humorous Headlines},
  author={Hossain, Nabil and Krumm, John and Gamon, Michael},
  journal={arXiv preprint arXiv:1906.00274},
  year={2019}
}

@article{mnli,
  title={A broad-coverage challenge corpus for sentence understanding through inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1704.05426},
  year={2017}
}

@misc{movie-tmdb, author = {Kaggle}, publisher = {Kaggle}, title = {{TMDB 5000 Movie Dataset}}, year = {2018}, url = {https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata} }

@misc{movie-wiki, author = {Robischon, Justin}, publisher = {Kaggle}, title = {{Wikipedia Movie Plots}}, year = {2019}, url = {https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots} }

@article{news-popularity, title = {Multi-Source Social Feedback of Online News Feeds}, author = {Nuno Moniz and Luâ€™is Torgo}, year = {2018}, ee = {[Web Link]}, volume = {[Web Link]}, journal = {CoRR}, }

@misc{nli-benchmarks, title = "WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation", author = "Liu, Alisa  and Swayamdipta, Swabha  and Smith, Noah A.  and Choi, Yejin", month = jan, year = "2022", url = "https://arxiv.org/pdf/2201.05955", }

@article{npt-conferences,
  title={Is the NPT unraveling? Evidence from text analysis of review conference statements},
  author={Barnum, Miriam and Lo, James},
  journal={Journal of Peace Research},
  volume={57},
  number={6},
  pages={740--751},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{open-deception,
  title={Experiments in open domain deception detection},
  author={P{\'e}rez-Rosas, Ver{\'o}nica and Mihalcea, Rada},
  booktitle={Proceedings of the 2015 conference on empirical methods in natural language processing},
  pages={1120--1125},
  year={2015}
}

@misc{oral-histories,
title={Oral History Text Analysis Project},
author={Freedman, Estelle and Marine-Street, Natalie}

}

@inproceedings{parenting-subreddits,
  title={Understanding the usage of online media for parenting from infancy to preschool at scale},
  author={Gao, Yujia and Jang, Jinu and Yang, Diyi},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2021}
}

@inproceedings{parenting-reddit-users,
  title={Understanding the usage of online media for parenting from infancy to preschool at scale},
  author={Gao, Yujia and Jang, Jinu and Yang, Diyi},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2021}
}

@misc{poetry, author = {Bramhecha, Divy}, publisher = {Kaggle}, title = {{Poetry Foundation Poems}}, year = {2019}, url = {https://www.kaggle.com/datasets/tgdivy/poetry-foundation-poems} }


@misc{political-ads, title = {Ad Observer},  year = {2021}, howpublished = {https://adobserver.org/} , note = {Accessed: 2022-12-30}}

@misc{qqp, author = {Quora}, publisher = {Kaggle}, title = {{Quora Question Pairs}}, year = {2017}, url = {https://www.kaggle.com/c/quora-question-pairs} }

@misc{rate-my-prof, author = {He, Jibo}, publisher = {Mendeley Data}, title = {{Big Data Set from RateMyProfessor.com for Professors' Teaching Evaluation}}, year = {2020}, url = {https://data.mendeley.com/datasets/fvtfjyvw7d/2} }

@article{veselovsky2023artificial,
  title={Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks},
  author={Veselovsky, Veniamin and Ribeiro, Manoel Horta and West, Robert},
  journal={arXiv preprint arXiv:2306.07899},
  year={2023}
}

@inproceedings{radiology-diagnosis,
    title = "A shared task involving multi-label classification of clinical free text",
    author = "Pestian, John P.  and
      Brew, Chris  and
      Matykiewicz, Pawel  and
      Hovermale, DJ  and
      Johnson, Neil  and
      Cohen, K. Bretonnel  and
      Duch, Wlodzislaw",
    booktitle = "Biological, translational, and clinical language processing",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W07-1013",
    pages = "97--104",
}

@inproceedings{suhr2021crowdsourcing,
  title={Crowdsourcing beyond annotation: Case studies in benchmark data collection},
  author={Suhr, Alane and Vania, Clara and Nangia, Nikita and Sap, Maarten and Yatskar, Mark and Bowman, Samuel and Artzi, Yoav},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts},
  pages={1--6},
  year={2021}
}


@article{wang2023goal,
  title={Goal-Driven Explainable Clustering via Language Descriptions},
  author={Wang, Zihan and Shang, Jingbo and Zhong, Ruiqi},
  journal={arXiv preprint arXiv:2305.13749},
  year={2023}
}

@article{ma2023demonstration,
  title={Demonstration of InsightPilot: An LLM-Empowered Automated Data Exploration System},
  author={Ma, Pingchuan and Ding, Rui and Wang, Shuai and Han, Shi and Zhang, Dongmei},
  journal={arXiv preprint arXiv:2304.00477},
  year={2023}
}


@inproceedings{reddit-humor,
    title = "The r{J}okes Dataset: a Large Scale Humor Collection",
    author = "Weller, Orion  and
      Seppi, Kevin",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.753",
    pages = "6136--6141",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@article{reddit-stress,
  title={Dreaddit: A Reddit dataset for stress analysis in social media},
  author={Turcan, Elsbeth and McKeown, Kathleen},
  journal={arXiv preprint arXiv:1911.00133},
  year={2019}
}

@misc{reuters-authorship, author = {Liu, Zhi}, publisher = {UCI Machine Learning Data Repository}, title = {{Reuter\_50\_50 Data Set}}, year = {2011}, url = {https://archive.ics.uci.edu/ml/datasets/Reuter_50_50} }

@article{scotus-cases,
  title={JUSTICE: A Benchmark Dataset for Supreme Court's Judgment Prediction},
  author={Alali, Mohammad and Syed, Shaayan and Alsayed, Mohammed and Patel, Smit and Bodala, Hemanth},
  journal={arXiv preprint arXiv:2112.03414},
  year={2021}
}

@misc{short-answer-scoring,
    title = {The Hewlett Foundation: Short Answer Scoring},
    publisher = {Kaggle},
    year = {2013},
    url = {https://kaggle.com/competitions/asap-sas}
}

@article{snli,
  title={The SNLI corpus},
  author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},
  year={2015}
}

@article{squad-v2,
  title={Know what you don't know: Unanswerable questions for SQuAD},
  author={Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  journal={arXiv preprint arXiv:1806.03822},
  year={2018}
}

@article{yang2022language,
  title={Language Models as Inductive Reasoners},
  author={Yang, Zonglin and Dong, Li and Du, Xinya and Cheng, Hao and Cambria, Erik and Liu, Xiaodong and Gao, Jianfeng and Wei, Furu},
  journal={arXiv preprint arXiv:2212.10923},
  year={2022}
}

@misc{stock-news, author = {Sun, J}, publisher = {Kaggle}, title = {{Daily News for Stock Market Prediction}}, year = {2017}, url = {https://www.kaggle.com/datasets/aaron7sun/stocknews} }

@misc{suicide-notes,
  author = {He, Samuel},
  title = {GOODBYE WORLD: using Natural Language Processing to identify suicidal posts},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/hesamuel/goodbye_world},
  commit = {4f837f89d96560d0bb6003e87fa042f6269cee38}
}

@misc{times-india-headlines, author = {Kulkarni, Rohit}, publisher = {Kaggle}, title = {{India News Headlines Dataset}}, year = {2022}, url = {https://www.kaggle.com/datasets/therohk/india-headlines-news-dataset} }

@inproceedings{trial-deception,
  title={Deception detection using real-life trial data},
  author={P{\'e}rez-Rosas, Ver{\'o}nica and Abouelenien, Mohamed and Mihalcea, Rada and Burzo, Mihai},
  booktitle={Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
  pages={59--66},
  year={2015}
}

@misc{tweet-gender, author = {Figure Eight}, publisher = {Kaggle}, title = {{Twitter User Gender Classification}}, year = {2017}, url = {https://www.kaggle.com/datasets/crowdflower/twitter-user-gender-classification} }

@article{tweet-rumor,
  title={The characteristics of rumor spreaders on Twitter: A quantitative analysis on real data},
  author={Bodaghi, Amirhosein and Oliveira, Jonice},
  journal={Computer Communications},
  volume={160},
  pages={674--687},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{twitter-bots,
  title={The paradigm-shift of social spambots: Evidence, theories, and tools for the arms race},
  author={Cresci, Stefano and Di Pietro, Roberto and Petrocchi, Marinella and Spognardi, Angelo and Tesconi, Maurizio},
  booktitle={Proceedings of the 26th international conference on world wide web companion},
  pages={963--972},
  year={2017}
}
@article{twitter-bots2,
  title={Social fingerprinting: detection of spambot groups through DNA-inspired behavioral modeling},
  author={Cresci, Stefano and Di Pietro, Roberto and Petrocchi, Marinella and Spognardi, Angelo and Tesconi, Maurizio},
  journal={IEEE Transactions on Dependable and Secure Computing},
  volume={15},
  number={4},
  pages={561--576},
  year={2017},
  publisher={IEEE}
}

@article{twitter-sentiment140,
  title={Twitter sentiment classification using distant supervision},
  author={Go, Alec and Bhayani, Richa and Huang, Lei},
  journal={CS224N project report, Stanford},
  volume={1},
  number={12},
  pages={2009},
  year={2009}
}

@article{bilodeau2024impossibility,
  title={Impossibility theorems for feature attribution},
  author={Bilodeau, Blair and Jaques, Natasha and Koh, Pang Wei and Kim, Been},
  journal={Proceedings of the National Academy of Sciences},
  volume={121},
  number={2},
  pages={e2304406120},
  year={2024},
  publisher={National Academy of Sciences}
}

@article{un-debates,
  title={Understanding state preferences with text as data: Introducing the UN General Debate corpus},
  author={Baturo, Alexander and Dasandi, Niheer and Mikhaylov, Slava J},
  journal={Research \& Politics},
  volume={4},
  number={2},
  pages={2053168017712821},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{unhealthy-conversations,
  title={Six attributes of unhealthy conversation},
  author={Price, Ilan and Gifford-Moore, Jordan and Fleming, Jory and Musker, Saul and Roichman, Maayan and Sylvain, Guillaume and Thain, Nithum and Dixon, Lucas and Sorensen, Jeffrey},
  journal={arXiv preprint arXiv:2010.07410},
  year={2020}
}

@misc{urban-dictionary, author = {Kulkarni, Rohit}, publisher = {Kaggle}, title = {{Urban Dictionary Words And Definitions}}, year = {2020}, url = {https://www.kaggle.com/datasets/therohk/urban-dictionary-words-dataset} }

@misc{wikitext,
      title={Pointer Sentinel Mixture Models},
      author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},
      year={2016},
      eprint={1609.07843},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@misc{yc-startups,
  author = {Akshay Bhalotia},
  title = {YC Company Scraper},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/akshaybhalotia/yc_company_scraper}},
  commit = {b564937bd35acc248a1ea7fb14a4e6c51090415b}
}


@article{chakravartty2011scientific,
  title={Scientific realism},
  author={Chakravartty, Anjan},
  year={2011}
}

@article{ludwig2022algorithmic,
  title={Algorithmic behavioral science: Machine learning as a tool for scientific discovery},
  author={Ludwig, Jens and Mullainathan, Sendhil},
  journal={Chicago Booth Research Paper},
  number={22-15},
  year={2022}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@book{stern2004wittgenstein,
  title={Wittgenstein's Philosophical investigations: an introduction},
  author={Stern, David G},
  volume={2},
  year={2004},
  publisher={Cambridge University Press}
}

@InProceedings{hernandez2022natural,
  title     =   {Natural Language Descriptions of Deep Visual Features},
  author    =   {Hernandez, Evan and Schwettmann, Sarah and Bau, David and Bagashvili, Teona and Torralba, Antonio and Andreas, Jacob},
  booktitle =   {International Conference on Learning Representations},
  year      =   {2022},
  url       =   {https://arxiv.org/abs/2201.11114}
}

@article{wang2022benchmarking,
  title={Benchmarking Generalization via In-Context Instructions on 1,600+ Language Tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  journal={arXiv preprint arXiv:2204.07705},
  year={2022}
}

@book{polanyi2009tacit,
  title={The tacit dimension},
  author={Polanyi, Michael and Sen, Amartya},
  year={2009},
  publisher={University of Chicago press}
}

@article{chang2009reading,
  title={Reading tea leaves: How humans interpret topic models},
  author={Chang, Jonathan and Gerrish, Sean and Wang, Chong and Boyd-Graber, Jordan and Blei, David},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}


@inproceedings{zhong-etal-2021-adapting-language,
    title = "Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections",
    author = "Zhong, Ruiqi  and
      Lee, Kristy  and
      Zhang, Zheng  and
      Klein, Dan",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.244",
    pages = "2856--2878",
    abstract = "Large pre-trained language models (LMs) such as GPT-3 have acquired a surprising ability to perform zero-shot learning. For example, to classify sentiment without any training examples, we can {``}prompt{''} the LM with the review and the label description {``}Does the user like this movie?{''}, and ask whether the next word is {``}yes{''} or {``}no{''}. However, the next word prediction training objective is still misaligned with the target zero-shot learning objective. To address this weakness, we propose meta-tuning, which directly optimizes the zero-shot learning objective by fine-tuning pre-trained language models on a collection of datasets. We focus on classification tasks, and construct the meta-dataset by aggregating 43 existing datasets and annotating 441 label descriptions in a question-answering (QA) format. When evaluated on unseen tasks, meta-tuned models outperform a same-sized QA model and the previous SOTA zero-shot learning system based on natural language inference. Additionally, increasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3{\%}, and we forecast that even larger models would perform better. Therefore, measuring zero-shot learning performance on language models out-of-the-box might underestimate their true potential, and community-wide efforts on aggregating datasets and unifying their formats can help build models that answer prompts better.",
}

@inproceedings{gao-etal-2021-making,
    title = "Making Pre-trained Language Models Better Few-shot Learners",
    author = "Gao, Tianyu  and
      Fisch, Adam  and
      Chen, Danqi",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.295",
    doi = "10.18653/v1/2021.acl-long.295",
    pages = "3816--3830",
    abstract = "The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot performance solely by leveraging a natural-language prompt and a few task demonstrations as input context. Inspired by their findings, we study few-shot learning in a more practical scenario, where we use smaller language models for which fine-tuning is computationally efficient. We present LM-BFF{---}better few-shot fine-tuning of language models{---}a suite of simple and complementary techniques for fine-tuning language models on a small number of annotated examples. Our approach includes (1) prompt-based fine-tuning together with a novel pipeline for automating prompt generation; and (2) a refined strategy for dynamically and selectively incorporating demonstrations into each context. Finally, we present a systematic evaluation for analyzing few-shot performance on a range of NLP tasks, including classification and regression. Our experiments demonstrate that our methods combine to dramatically outperform standard fine-tuning procedures in this low resource setting, achieving up to 30{\%} absolute improvement, and 11{\%} on average across all tasks. Our approach makes minimal assumptions on task resources and domain expertise, and hence constitutes a strong task-agnostic method for few-shot learning.",
}

@article{min2021noisy,
  title={Noisy channel language model prompting for few-shot text classification},
  author={Min, Sewon and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2108.04106},
  year={2021}
}

@article{mishra2021reframing,
  title={Reframing Instructional Prompts to GPTk's Language},
  author={Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Choi, Yejin and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2109.07830},
  year={2021}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{rubin2021learning,
  title={Learning To Retrieve Prompts for In-Context Learning},
  author={Rubin, Ohad and Herzig, Jonathan and Berant, Jonathan},
  journal={arXiv preprint arXiv:2112.08633},
  year={2021}
}

@article{wortsman2021robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Li, Mike and Kim, Jong Wook and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and Schmidt, Ludwig},
  journal={arXiv preprint arXiv:2109.01903},
  year={2021}
}

@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}

@inproceedings{Mishra2021CrossTaskGV,
  title={Cross-Task Generalization via Natural Language Crowdsourcing Instructions},
  author={Swaroop Mishra and Daniel Khashabi and Chitta Baral and Hannaneh Hajishirzi},
  year={2021}
}



@inproceedings{shin-etal-2020-autoprompt,
    title = "{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with {A}utomatically {G}enerated {P}rompts",
    author = "Shin, Taylor  and
      Razeghi, Yasaman  and
      Logan IV, Robert L.  and
      Wallace, Eric  and
      Singh, Sameer",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.346",
    doi = "10.18653/v1/2020.emnlp-main.346",
    pages = "4222--4235",
    abstract = "The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.",
}



@article{bragg2021flex,
  title={Flex: Unifying evaluation for few-shot nlp},
  author={Bragg, Jonathan and Cohan, Arman and Lo, Kyle and Beltagy, Iz},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{pang-lee-2004-sentimental,
    title = "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts",
    author = "Pang, Bo  and
      Lee, Lillian",
    booktitle = "Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04)",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    url = "https://aclanthology.org/P04-1035",
    doi = "10.3115/1218955.1218990",
    pages = "271--278",
}

@inproceedings{gomez2006content,
  title={Content based SMS spam filtering},
  author={G{\'o}mez Hidalgo, Jos{\'e} Mar{\'\i}a and Bringas, Guillermo Cajigas and S{\'a}nz, Enrique Puertas and Garc{\'\i}a, Francisco Carrero},
  booktitle={Proceedings of the 2006 ACM symposium on Document engineering},
  pages={107--114},
  year={2006}
}

@article{Sanh2021MultitaskPT,
  title={Multitask Prompted Training Enables Zero-Shot Task Generalization},
  author={Victor Sanh and Albert Webson and Colin Raffel and Stephen H. Bach and Lintang A. Sutawika and Zaid Alyafeai and Antoine Chaffin and Arnaud Stiegler and Teven Le Scao and Arun Raja and Manan Dey and M SAIFUL BARI and Canwen Xu and Urmish Thakker and Shanya Sharma Sharma and Eliza Szczechla and Taewoon Kim and Gunjan Chhablani and Nihal V. Nayak and Debajyoti Datta and Jonathan Chang and Mike Tian-Jian Jiang and Han Wang and Matteo Manica and Sheng Shen and Zheng Xin Yong and Harshit Pandey and Rachel Bawden and Thomas Wang and Trishala Neeraj and Jos Rozen and Abheesht Sharma and Andrea Santilli and Thibault F{\'e}vry and Jason Alan Fries and Ryan Teehan and Stella Rose Biderman and Leo Gao and T. G. Owe Bers and Thomas Wolf and Alexander M. Rush},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.08207}
}

@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.353",
    doi = "10.18653/v1/2021.acl-long.353",
    pages = "4582--4597",
    abstract = "Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were {``}virtual tokens{''}. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by learning only 0.1{\%} of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.",
}

@article{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  journal={arXiv preprint arXiv:2103.00020},
  year={2021}
}

@inproceedings{fried2014analyzing,
  title={Analyzing the language of food on social media},
  author={Fried, Daniel and Surdeanu, Mihai and Kobourov, Stephen and Hingle, Melanie and Bell, Dane},
  booktitle={2014 IEEE International Conference on Big Data (Big Data)},
  pages={778--783},
  year={2014},
  organization={IEEE}
}

@article{barchiesi2015acoustic,
  title={Acoustic scene classification: Classifying environments from the sounds they produce},
  author={Barchiesi, Daniele and Giannoulis, Dimitrios and Stowell, Dan and Plumbley, Mark D},
  journal={IEEE Signal Processing Magazine},
  volume={32},
  number={3},
  pages={16--34},
  year={2015},
  publisher={IEEE}
}


@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}


@article{lucy2020content,
  title={Content analysis of textbooks via natural language processing: Findings on gender, race, and ethnicity in Texas US history textbooks},
  author={Lucy, Li and Demszky, Dorottya and Bromley, Patricia and Jurafsky, Dan},
  journal={AERA Open},
  volume={6},
  number={3},
  pages={2332858420940312},
  year={2020},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{zhang2021deep,
  title = {Deep Understanding and Generation of Medical Text and Beyond},
  author = {Zhang, Yuhao},
  year = {2021},
  journal = {Stanford University PhD Thesis},
  school = {Stanford University},
  html = {https://searchworks.stanford.edu/view/13826064},
  abbr = {Thesis},
  bibtex_show = {true},
  selected = {true}
}

@inproceedings{
anonymous2022natural,
title={Natural Language Descriptions of Deep Features},
author={Anonymous},
booktitle={Submitted to The Tenth International Conference on Learning Representations },
year={2022},
url={https://openreview.net/forum?id=NudBMY-tzDr},
note={under review}
}

@article{sap2021annotators,
  title={Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection},
  author={Sap, Maarten and Swayamdipta, Swabha and Vianna, Laura and Zhou, Xuhui and Choi, Yejin and Smith, Noah A},
  journal={arXiv preprint arXiv:2111.07997},
  year={2021}
}

@book{imbens2015causal,
  title={Causal inference in statistics, social, and biomedical sciences},
  author={Imbens, Guido W and Rubin, Donald B},
  year={2015},
  publisher={Cambridge University Press}
}

@inproceedings{Demszky2019AnalyzingPI,
  title={Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings},
  author={Dorottya Demszky and Nikhil Garg and Rob Voigt and James Y. Zou and Matthew Gentzkow and Jesse M. Shapiro and Dan Jurafsky},
  booktitle={NAACL},
  year={2019}
}

@article{hendrycks2021cuad,
  title={Cuad: An expert-annotated nlp dataset for legal contract review},
  author={Hendrycks, Dan and Burns, Collin and Chen, Anya and Ball, Spencer},
  journal={arXiv preprint arXiv:2103.06268},
  year={2021}
}

@article{nakano2021webgpt,
  title={WebGPT: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@article{lipton2018mythos,
  title={The Mythos of Model Interpretability: In machine learning, the concept of interpretability is both important and slippery.},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@book{anzai2012pattern,
  title={Pattern recognition and machine learning},
  author={Anzai, Yuichiro},
  year={2012},
  publisher={Elsevier}
}

@article{williams1990toward,
  title={Toward Clarity and Grace},
  author={Williams, Joseph},
  journal={Chicago: The University of Chicago},
  year={1990}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{Kitaev2020ReformerTE,
  title={Reformer: The Efficient Transformer},
  author={Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.04451}
}

@article{khashabi2021prompt,
  title={PROMPT WAYWARDNESS: The Curious Case of Discretized Interpretation of Continuous Prompts},
  author={Khashabi, Daniel and Lyu, Shane and Min, Sewon and Qin, Lianhui and Richardson, Kyle and Singh, Sameer and Welleck, Sean and Hajishirzi, Hannaneh and Khot, Tushar and Sabharwal, Ashish and others},
  journal={arXiv preprint arXiv:2112.08348},
  year={2021}
}

@inproceedings{song-etal-2020-adversarial,
    title = "Adversarial Semantic Collisions",
    author = "Song, Congzheng  and
      Rush, Alexander  and
      Shmatikov, Vitaly",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.344",
    doi = "10.18653/v1/2020.emnlp-main.344",
    pages = "4198--4210",
    abstract = "We study \textit{semantic collisions}: texts that are semantically unrelated but judged as similar by NLP models. We develop gradient-based approaches for generating semantic collisions and demonstrate that state-of-the-art models for many tasks which rely on analyzing the meaning and similarity of texts{---}including paraphrase identification, document retrieval, response suggestion, and extractive summarization{---}are vulnerable to semantic collisions. For example, given a target query, inserting a crafted collision into an irrelevant document can shift its retrieval rank from 1000 to top 3. We show how to generate semantic collisions that evade perplexity-based filtering and discuss other potential mitigations. Our code is available at \url{https://github.com/csong27/collision-bert}.",
}

@inproceedings{clark-etal-2019-boolq,
    title = "{B}ool{Q}: Exploring the Surprising Difficulty of Natural Yes/No Questions",
    author = "Clark, Christopher  and
      Lee, Kenton  and
      Chang, Ming-Wei  and
      Kwiatkowski, Tom  and
      Collins, Michael  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1300",
    doi = "10.18653/v1/N19-1300",
    pages = "2924--2936",
    abstract = "In this paper we study yes/no questions that are naturally occurring {---} meaning that they are generated in unprompted and unconstrained settings. We build a reading comprehension dataset, BoolQ, of such questions, and show that they are unexpectedly challenging. They often query for complex, non-factoid information, and require difficult entailment-like inference to solve. We also explore the effectiveness of a range of transfer learning baselines. We find that transferring from entailment data is more effective than transferring from paraphrase or extractive QA data, and that it, surprisingly, continues to be very beneficial even when starting from massive pre-trained language models such as BERT. Our best method trains BERT on MultiNLI and then re-trains it on our train set. It achieves 80.4{\%} accuracy compared to 90{\%} accuracy of human annotators (and 62{\%} majority-baseline), leaving a significant gap for future work.",
}

@article{zeng2002modeling,
  title={Modeling the effects of epidemics on routinely collected data},
  author={Zeng, Xiaoming and Wagner, Michael},
  journal={Journal of the American Medical Informatics Association},
  volume={9},
  number={Supplement\_6},
  pages={S17--S22},
  year={2002},
  publisher={BMJ Group BMA House, Tavistock Square, London, WC1H 9JR}
}

@article{gentzkow2019text,
  title={Text as data},
  author={Gentzkow, Matthew and Kelly, Bryan and Taddy, Matt},
  journal={Journal of Economic Literature},
  volume={57},
  number={3},
  pages={535--74},
  year={2019}
}

@article{boyd2015did,
  title={Did Shakespeare write Double Falsehood? Identifying individuals by creating psychological signatures with text analysis},
  author={Boyd, Ryan L and Pennebaker, James W},
  journal={Psychological science},
  volume={26},
  number={5},
  pages={570--582},
  year={2015},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{rae2021scaling,
  title={Scaling Language Models: Methods, Analysis \& Insights from Training Gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@inproceedings{desai-durrett-2020-calibration,
    title = "Calibration of Pre-trained Transformers",
    author = "Desai, Shrey  and
      Durrett, Greg",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.21",
    doi = "10.18653/v1/2020.emnlp-main.21",
    pages = "295--302",
    abstract = "Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated. Specifically, do these models{'} posterior probabilities provide an accurate empirical measure of how likely the model is to be correct on a given example? We focus on BERT and RoBERTa in this work, and analyze their calibration across three tasks: natural language inference, paraphrase detection, and commonsense reasoning. For each task, we consider in-domain as well as challenging out-of-domain settings, where models face more examples they should be uncertain about. We show that: (1) when used out-of-the-box, pre-trained models are calibrated in-domain, and compared to baselines, their calibration error out-of-domain can be as much as 3.5x lower; (2) temperature scaling is effective at further reducing calibration error in-domain, and using label smoothing to deliberately increase empirical uncertainty helps calibrate posteriors out-of-domain.",
}

@inproceedings{zhou-etal-2020-curse,
    title = "The Curse of Performance Instability in Analysis Datasets: Consequences, Source, and Suggestions",
    author = "Zhou, Xiang  and
      Nie, Yixin  and
      Tan, Hao  and
      Bansal, Mohit",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.659",
    doi = "10.18653/v1/2020.emnlp-main.659",
    pages = "8215--8228",
    abstract = "We find that the performance of state-of-the-art models on Natural Language Inference (NLI) and Reading Comprehension (RC) analysis/stress sets can be highly unstable. This raises three questions: (1) How will the instability affect the reliability of the conclusions drawn based on these analysis sets? (2) Where does this instability come from? (3) How should we handle this instability and what are some potential solutions? For the first question, we conduct a thorough empirical study over analysis sets and find that in addition to the unstable final performance, the instability exists all along the training curve. We also observe lower-than-expected correlations between the analysis validation set and standard validation set, questioning the effectiveness of the current model-selection routine. Next, to answer the second question, we give both theoretical explanations and empirical evidence regarding the source of the instability, demonstrating that the instability mainly comes from high inter-example correlations within analysis sets. Finally, for the third question, we discuss an initial attempt to mitigate the instability and suggest guidelines for future work such as reporting the decomposed variance for more interpretable results and fair comparison across models.",
}

@article{Sagawa2019DistributionallyRN,
  title={Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization},
  author={Shiori Sagawa and Pang Wei Koh and Tatsunori B. Hashimoto and Percy Liang},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.08731}
}

@article{Liu2019RoBERTaAR,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.11692}
}

@inproceedings{naik-etal-2018-stress,
    title = "Stress Test Evaluation for Natural Language Inference",
    author = "Naik, Aakanksha  and
      Ravichander, Abhilasha  and
      Sadeh, Norman  and
      Rose, Carolyn  and
      Neubig, Graham",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/C18-1198",
    pages = "2340--2353",
    abstract = "Natural language inference (NLI) is the task of determining if a natural language hypothesis can be inferred from a given premise in a justifiable manner. NLI was proposed as a benchmark task for natural language understanding. Existing models perform well at standard datasets for NLI, achieving impressive results across different genres of text. However, the extent to which these models understand the semantic content of sentences is unclear. In this work, we propose an evaluation methodology consisting of automatically constructed {``}stress tests{''} that allow us to examine whether systems have the ability to make real inferential decisions. Our evaluation of six sentence-encoder models on these stress tests reveals strengths and weaknesses of these models with respect to challenging linguistic phenomena, and suggests important directions for future work in this area.",
}


@inproceedings{hendrycks2021many,
  title={The many faces of robustness: A critical analysis of out-of-distribution generalization},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8340--8349},
  year={2021}
}

@article{kang2019testing,
  title={Testing robustness against unforeseen adversaries},
  author={Kang, Daniel and Sun, Yi and Hendrycks, Dan and Brown, Tom and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:1908.08016},
  year={2019}
}

@inproceedings{lan-etal-2017-continuously,
    title = "A Continuously Growing Dataset of Sentential Paraphrases",
    author = "Lan, Wuwei  and
      Qiu, Siyu  and
      He, Hua  and
      Xu, Wei",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1126",
    doi = "10.18653/v1/D17-1126",
    pages = "1224--1234",
    abstract = "A major challenge in paraphrase research is the lack of parallel corpora. In this paper, we present a new method to collect large-scale sentential paraphrases from Twitter by linking tweets through shared URLs. The main advantage of our method is its simplicity, as it gets rid of the classifier or human in the loop needed to select data before annotation and subsequent application of paraphrase identification algorithms in the previous work. We present the largest human-labeled paraphrase corpus to date of 51,524 sentence pairs and the first cross-domain benchmarking for automatic paraphrase identification. In addition, we show that more than 30,000 new sentential paraphrases can be easily and continuously captured every month at {\textasciitilde}70{\%} precision, and demonstrate their utility for downstream NLP tasks through phrasal paraphrase extraction. We make our code and data freely available.",
}


@article{sagawa2019distributionally,
  title={Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  journal={arXiv preprint arXiv:1911.08731},
  year={2019}
}

@article{Wei2021FinetunedLM,
  title={Finetuned Language Models Are Zero-Shot Learners},
  author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.01652}
}

@inproceedings{hardt2016strategic,
  title={Strategic classification},
  author={Hardt, Moritz and Megiddo, Nimrod and Papadimitriou, Christos and Wootters, Mary},
  booktitle={Proceedings of the 2016 ACM conference on innovations in theoretical computer science},
  pages={111--122},
  year={2016}
}

@inproceedings{gururangan-etal-2018-annotation,
    title = "Annotation Artifacts in Natural Language Inference Data",
    author = "Gururangan, Suchin  and
      Swayamdipta, Swabha  and
      Levy, Omer  and
      Schwartz, Roy  and
      Bowman, Samuel  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2017",
    doi = "10.18653/v1/N18-2017",
    pages = "107--112",
    abstract = "Large-scale datasets for natural language inference are created by presenting crowd workers with a sentence (premise), and asking them to generate three new sentences (hypotheses) that it entails, contradicts, or is logically neutral with respect to. We show that, in a significant portion of such data, this protocol leaves clues that make it possible to identify the label by looking only at the hypothesis, without observing the premise. Specifically, we show that a simple text categorization model can correctly classify the hypothesis alone in about 67{\%} of SNLI (Bowman et. al, 2015) and 53{\%} of MultiNLI (Williams et. al, 2017). Our analysis reveals that specific linguistic phenomena such as negation and vagueness are highly correlated with certain inference classes. Our findings suggest that the success of natural language inference models to date has been overestimated, and that the task remains a hard open problem.",
}

@inproceedings{williams-etal-2018-broad,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1101",
    doi = "10.18653/v1/N18-1101",
    pages = "1112--1122",
    abstract = "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",
}

@inproceedings{khashabi-etal-2020-unifiedqa,
    title = "{UNIFIEDQA}: Crossing Format Boundaries with a Single {QA} System",
    author = "Khashabi, Daniel  and
      Min, Sewon  and
      Khot, Tushar  and
      Sabharwal, Ashish  and
      Tafjord, Oyvind  and
      Clark, Peter  and
      Hajishirzi, Hannaneh",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.171",
    doi = "10.18653/v1/2020.findings-emnlp.171",
    pages = "1896--1907",
    abstract = "Question answering (QA) tasks have been posed using a variety of formats, such as extractive span selection, multiple choice, etc. This has led to format-specialized models, and even to an implicit division in the QA community. We argue that such boundaries are artificial and perhaps unnecessary, given the reasoning abilities we seek to teach are not governed by the format. As evidence, we use the latest advances in language modeling to build a single pre-trained QA model, UNIFIEDQA, that performs well across 19 QA datasets spanning 4 diverse formats. UNIFIEDQA performs on par with 8 different models that were trained on individual datasets themselves. Even when faced with 12 unseen datasets of observed formats, UNIFIEDQA performs surprisingly well, showing strong generalization from its outof-format training data. Finally, simply finetuning this pre trained QA model into specialized models results in a new state of the art on 10 factoid and commonsense question answering datasets, establishing UNIFIEDQA as a strong starting point for building QA systems.",
}
Download as File
Copy to Clipboard

@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}

@inproceedings{bowman-etal-2015-large,
    title = "A large annotated corpus for learning natural language inference",
    author = "Bowman, Samuel R.  and
      Angeli, Gabor  and
      Potts, Christopher  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1075",
    doi = "10.18653/v1/D15-1075",
    pages = "632--642",
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@misc{merity2016pointer,
      title={Pointer Sentinel Mixture Models}, 
      author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},
      year={2016},
      eprint={1609.07843},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{aharoni2020unsupervised,
      title={Unsupervised Domain Clusters in Pretrained Language Models}, 
      author={Roee Aharoni and Yoav Goldberg},
      year={2020},
      eprint={2004.02105},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{reimers2019sentencebert,
      title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}, 
      author={Nils Reimers and Iryna Gurevych},
      year={2019},
      eprint={1908.10084},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@book{breiman2017classification,
  title={Classification and regression trees},
  author={Breiman, Leo and Friedman, Jerome H and Olshen, Richard A and Stone, Charles J},
  year={2017},
  publisher={Routledge}
}


@article{2008,
   title={Predictive learning via rule ensembles},
   volume={2},
   ISSN={1932-6157},
   url={http://dx.doi.org/10.1214/07-AOAS148},
   DOI={10.1214/07-aoas148},
   number={3},
   journal={The Annals of Applied Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Friedman, Jerome H. and Popescu, Bogdan E.},
   year={2008},
   month={Sep}
}

@article{10.2307/2346178,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2346178},
 abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
 author = {Robert Tibshirani},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {267--288},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Regression Shrinkage and Selection via the Lasso},
 volume = {58},
 year = {1996}
}

@article{zhong2024explaining,
  title={Explaining datasets in words: Statistical models with natural language parameters},
  author={Zhong, Ruiqi and Wang, Heng and Klein, Dan and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={79350--79380},
  year={2024}
}

@article{OLSHAUSEN19973311,
title = {Sparse coding with an overcomplete basis set: A strategy employed by V1?},
journal = {Vision Research},
volume = {37},
number = {23},
pages = {3311-3325},
year = {1997},
issn = {0042-6989},
doi = {https://doi.org/10.1016/S0042-6989(97)00169-7},
url = {https://www.sciencedirect.com/science/article/pii/S0042698997001697},
author = {Bruno A. Olshausen and David J. Field},
keywords = {Coding, V1, Gabor-wavelet, Natural images},
abstract = {The spatial receptive fields of simple cells in mammalian striate cortex have been reasonably well described physiologically and can be characterized as being localized, oriented, and bandpass, comparable with the basis functions of wavelet transforms. Previously, we have shown that these receptive field properties may be accounted for in terms of a strategy for producing a sparse distribution of output activity in response to natural images. Here, in addition to describing this work in a more expansive fashion, we examine the neurobiological implications of sparse coding. Of particular interest is the case when the code is overcomplete—i.e., when the number of code elements is greater than the effective dimensionality of the input space. Because the basis functions are non-orthogonal and not linearly independent of each other, sparsifying the code will recruit only those basis functions necessary for representing a given input, and so the input-output function will deviate from being purely linear. These deviations from linearity provide a potential explanation for the weak forms of non-linearity observed in the response properties of cortical simple cells, and they further make predictions about the expected interactions among units in response to naturalistic stimuli.}
}

@INPROCEEDINGS{342465,
  author={Pati, Y.C. and Rezaiifar, R. and Krishnaprasad, P.S.},
  booktitle={Proceedings of 27th Asilomar Conference on Signals, Systems and Computers}, 
  title={Orthogonal matching pursuit: recursive function approximation with applications to wavelet decomposition}, 
  year={1993},
  volume={},
  number={},
  pages={40-44 vol.1},
  doi={10.1109/ACSSC.1993.342465}}

@misc{abbasiasl2020structural,
      title={Structural Compression of Convolutional Neural Networks}, 
      author={Reza Abbasi-Asl and Bin Yu},
      year={2020},
      eprint={1705.07356},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{OLDEN2004389,
title = {An accurate comparison of methods for quantifying variable importance in artificial neural networks using simulated data},
journal = {Ecological Modelling},
volume = {178},
number = {3},
pages = {389-397},
year = {2004},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2004.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0304380004001565},
author = {Julian D Olden and Michael K Joy and Russell G Death},
keywords = {Statistical models, Explanatory power, Connection weights, Garson’s algorithm, Sensitivity analysis},
abstract = {Artificial neural networks (ANNs) are receiving greater attention in the ecological sciences as a powerful statistical modeling technique; however, they have also been labeled a “black box” because they are believed to provide little explanatory insight into the contributions of the independent variables in the prediction process. A recent paper published in Ecological Modelling [Review and comparison of methods to study the contribution of variables in artificial neural network models, Ecol. Model. 160 (2003) 249–264] addressed this concern by providing a comprehensive comparison of eight different methodologies for estimating variable importance in neural networks that are commonly used in ecology. Unfortunately, comparisons of the different methodologies were based on an empirical dataset, which precludes the ability to establish generalizations regarding the true accuracy and precision of the different approaches because the true importance of the variables is unknown. Here, we provide a more appropriate comparison of the different methodologies by using Monte Carlo simulations with data exhibiting defined (and consequently known) numeric relationships. Our results show that a Connection Weight Approach that uses raw input-hidden and hidden-output connection weights in the neural network provides the best methodology for accurately quantifying variable importance and should be favored over the other approaches commonly used in the ecological literature. Average similarity between true and estimated ranked variable importance using this approach was 0.92, whereas, similarity coefficients ranged between 0.28 and 0.74 for the other approaches. Furthermore, the Connection Weight Approach was the only method that consistently identified the correct ranked importance of all predictor variables, whereas, the other methods either only identified the first few important variables in the network or no variables at all. The most notably result was that Garson’s Algorithm was the poorest performing approach, yet is the most commonly used in the ecological literature. In conclusion, this study provides a robust comparison of different methodologies for assessing variable importance in neural networks that can be generalized to other data and from which valid recommendations can be made for future studies.}
}

@misc{tsang2018detecting,
      title={Detecting Statistical Interactions from Neural Network Weights}, 
      author={Michael Tsang and Dehua Cheng and Yan Liu},
      year={2018},
      eprint={1705.04977},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}



@InProceedings{maas-EtAl:2011:ACL-HLT2011,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@article{warstadt2018neural,
    title={Neural Network Acceptability Judgments},
    author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
    journal={arXiv preprint arXiv:1805.12471},
    year={2018}
}

@inproceedings{barbieri-etal-2020-tweeteval,
    title = "{T}weet{E}val: Unified Benchmark and Comparative Evaluation for Tweet Classification",
    author = "Barbieri, Francesco  and
      Camacho-Collados, Jose  and
      Espinosa Anke, Luis  and
      Neves, Leonardo",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.148",
    doi = "10.18653/v1/2020.findings-emnlp.148",
    pages = "1644--1650",
    abstract = "The experimental landscape in natural language processing for social media is too fragmented. Each year, new shared tasks and datasets are proposed, ranging from classics like sentiment analysis to irony detection or emoji prediction. Therefore, it is unclear what the current state of the art is, as there is no standardized evaluation protocol, neither a strong set of baselines trained on such domain-specific data. In this paper, we propose a new evaluation framework (TweetEval) consisting of seven heterogeneous Twitter-specific classification tasks. We also provide a strong set of baselines as starting point, and compare different language modeling pre-training strategies. Our initial experiments show the effectiveness of starting off with existing pre-trained generic language models, and continue training them on Twitter corpora.",
}

@inproceedings{yin-etal-2019-benchmarking,
    title = "Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach",
    author = "Yin, Wenpeng  and
      Hay, Jamaal  and
      Roth, Dan",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1404",
    doi = "10.18653/v1/D19-1404",
    pages = "3914--3923",
    abstract = "Zero-shot text classification (0Shot-TC) is a challenging NLU problem to which little attention has been paid by the research community. 0Shot-TC aims to associate an appropriate label with a piece of text, irrespective of the text domain and the aspect (e.g., topic, emotion, event, etc.) described by the label. And there are only a few articles studying 0Shot-TC, all focusing only on topical categorization which, we argue, is just the tip of the iceberg in 0Shot-TC. In addition, the chaotic experiments in literature make no uniform comparison, which blurs the progress. This work benchmarks the 0Shot-TC problem by providing unified datasets, standardized evaluations, and state-of-the-art baselines. Our contributions include: i) The datasets we provide facilitate studying 0Shot-TC relative to conceptually different and diverse aspects: the {``}topic{''} aspect includes {``}sports{''} and {``}politics{''} as labels; the {``}emotion{''} aspect includes {``}joy{''} and {``}anger{''}; the {``}situation{''} aspect includes {``}medical assistance{''} and {``}water shortage{''}. ii) We extend the existing evaluation setup (label-partially-unseen) {--} given a dataset, train on some labels, test on all labels {--} to include a more challenging yet realistic evaluation label-fully-unseen 0Shot-TC (Chang et al., 2008), aiming at classifying text snippets without seeing task specific training data at all. iii) We unify the 0Shot-TC of diverse aspects within a textual entailment formulation and study it this way.",
}

@article{almeida2013towards,
  title={Towards sms spam filtering: Results under a new dataset},
  author={Almeida, Tiago and Hidalgo, Jos{\'e} Mar{\'\i}a G{\'o}mez and Silva, Tiago Pasqualini},
  journal={International Journal of Information Security Science},
  volume={2},
  number={1},
  pages={1--18},
  year={2013}
}

@inproceedings{li2002learning,
  title={Learning question classifiers},
  author={Li, Xin and Roth, Dan},
  booktitle={COLING 2002: The 19th International Conference on Computational Linguistics},
  year={2002}
}

@inproceedings{mihaylova-etal-2019-semeval,
    title = "{S}em{E}val-2019 Task 8: Fact Checking in Community Question Answering Forums",
    author = "Mihaylova, Tsvetomila  and
      Karadzhov, Georgi  and
      Atanasova, Pepa  and
      Baly, Ramy  and
      Mohtarami, Mitra  and
      Nakov, Preslav",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-2149",
    doi = "10.18653/v1/S19-2149",
    pages = "860--869",
    abstract = "We present SemEval-2019 Task 8 on Fact Checking in Community Question Answering Forums, which features two subtasks. Subtask A is about deciding whether a question asks for factual information vs. an opinion/advice vs. just socializing. Subtask B asks to predict whether an answer to a factual question is true, false or not a proper answer. We received 17 official submissions for subtask A and 11 official submissions for Subtask B. For subtask A, all systems improved over the majority class baseline. For Subtask B, all systems were below a majority class baseline, but several systems were very close to it. The leaderboard and the data from the competition can be found at http://competitions.codalab.org/competitions/20022.",
}

@inproceedings{10.5555/2969239.2969312, author = {Zhang, Xiang and Zhao, Junbo and LeCun, Yann}, title = {Character-Level Convolutional Networks for Text Classification}, year = {2015}, publisher = {MIT Press}, address = {Cambridge, MA, USA}, abstract = {This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words, n-grams and their TFIDF variants, and deep learning models such as word-based ConvNets and recurrent neural networks.}, booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1}, pages = {649–657}, numpages = {9}, location = {Montreal, Canada}, series = {NIPS'15} }



% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{bansal2019beyond,
  title={Beyond accuracy: The role of mental models in human-AI team performance},
  author={Bansal, Gagan and Nushi, Besmira and Kamar, Ece and Lasecki, Walter S and Weld, Daniel S and Horvitz, Eric},
  booktitle={Proceedings of the AAAI conference on human computation and crowdsourcing},
  year={2019},
url={https://ojs.aaai.org/index.php/HCOMP/article/view/5285}
}

@article{collins1987people,
  title={How people construct mental models},
  author={Collins, Allan and Gentner, Dedre},
  journal={Cultural models in language and thought},
  year={1987},
url={https://doi.org/10.1017/CBO9780511607660.011}
}

@inproceedings{joshi2023machine,
    title = "Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-text Rationales",
    author = "Joshi, Brihi  and
      Liu, Ziyi  and
      Ramnath, Sahana  and
      Chan, Aaron  and
      Tong, Zhewei  and
      Nie, Shaoliang  and
      Wang, Qifan  and
      Choi, Yejin  and
      Ren, Xiang",
    booktitle = "Proceedings of the Association for Computational Linguistics",
    year = "2023",
    url = "https://aclanthology.org/2023.acl-long.392",
}

@book{garnham1987mental,
  title={Mental models as representations of discourse and text.},
  author={Garnham, Alan},
  year={1987},
url={https://psycnet.apa.org/record/1988-97459-000}
}

@article{johnson1980mental,
  title={Mental models in cognitive science},
  author={Johnson-Laird, Philip N},
  journal={Cognitive science},
  year={1980},
url={https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog0401_4}
}

@article{openai2023gpt4,
  title={GPT-4 Technical Report}, 
  author={OpenAI},
  year={2023},
  journal={ArXiv},
  url={https://arxiv.org/pdf/2303.08774.pdf}
}

@article{merry2021mental,
  title={A mental models approach for defining explainable artificial intelligence},
  author={Merry, Michael and Riddle, Pat and Warren, Jim},
  journal={BMC Medical Informatics and Decision Making},
  year={2021},
url={https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01703-7}
}

@techreport{cassidy2009mental,
  title={Mental models, trust, and reliance: Exploring the effect of human perceptions on automation use},
  author={Cassidy, Andrea M},
  year={2009},
url={http://edocs.nps.edu/npspubs/scholarly/theses/2009/Jun/09Jun_Cassidy.pdf}
}

@article{babic2021beware,
  title={Beware explanations from AI in health care},
  author={Babic, Boris and Gerke, Sara and Evgeniou, Theodoros and Cohen, I Glenn},
  journal={Science},
  year={2021},
url={https://www.science.org/doi/10.1126/science.abg1834}
}

@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={ArXiv},
  year={2017},
  url={https://arxiv.org/pdf/1702.08608.pdf}
}

@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  year={2018},
url={https://ojs.aaai.org/index.php/AAAI/article/view/11491}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{
wang2022self,
title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
booktitle={Proceedings of the International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=1PL1NIMMrw}
}

@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={ArXiv},
  url={https://arxiv.org/pdf/2112.00114.pdf}
}


@inproceedings{park2018multimodal,
  title={Multimodal explanations: Justifying decisions and pointing to the evidence},
  author={Park, Dong Huk and Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Anna and Schiele, Bernt and Darrell, Trevor and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018},
url={https://openaccess.thecvf.com/content_cvpr_2018/papers/Park_Multimodal_Explanations_Justifying_CVPR_2018_paper.pdf}
}

@InProceedings{pmlr-v162-ethayarajh22a,
  title = 	 {Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information},
  author =       {Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
  booktitle = 	 {Proceedings of the International Conference on Machine Learning},
  year = 	 {2022},
url={https://proceedings.mlr.press/v162/ethayarajh22a.html}}


@article{dubois2023alpacafarm,
  title={Alpacafarm: A simulation framework for methods that learn from human feedback},
  author={Dubois, Yann and Li, Xuechen and Taori, Rohan and Zhang, Tianyi and Gulrajani, Ishaan and Ba, Jimmy and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
journal={ArXiv},
url={https://arxiv.org/pdf/2305.14387.pdf}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={ArXiv},
url={https://arxiv.org/pdf/2204.05862.pdf},
  year={2022}
}

@inproceedings{adadi2020explainable,
  title={Explainable AI for healthcare: from black box to interpretable models},
  author={Adadi, Amina and Berrada, Mohammed},
  booktitle={Embedded Systems and Artificial Intelligence: Proceedings of ESAI 2019},
  year={2020},
url={https://link.springer.com/chapter/10.1007/978-981-15-0947-6_31}
}

@article{deeks2019judicial,
  title={The judicial demand for explainable artificial intelligence},
  author={Deeks, Ashley},
  journal={Columbia Law Review},
  year={2019},
url={https://www.jstor.org/stable/26810851}
}

@inproceedings{matulionyte2021call,
  title={A call for more explainable AI in law enforcement},
  author={Matulionyte, Rita and Hanif, Ambreen},
  booktitle={IEEE International Enterprise Distributed Object Computing Workshop (EDOCW)},
  year={2021},
url={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3974243}
}

@inproceedings{10.1145/3411763.3443441,
author = {Norkute, Milda and Herger, Nadja and Michalak, Leszek and Mulder, Andrew and Gao, Sally},
title = {Towards Explainable AI: Assessing the Usefulness and Impact of Added Explainability Features in Legal Document Summarization},
year = {2021},
url = {https://doi.org/10.1145/3411763.3443441},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
}

@article{hall2022explainable,
  title={Explainable artificial intelligence for digital forensics},
  author={Hall, Stuart W and Sakzad, Amin and Choo, Kim-Kwang Raymond},
  journal={Wiley Interdisciplinary Reviews: Forensic Science},
  year={2022},
url={https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wfs2.1434}
}

@inproceedings{NEURIPS2020_92650b2e,
 author = {Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Singer, Yaron and Shieber, Stuart},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 title = {Investigating Gender Bias in Language Models Using Causal Mediation Analysis},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/92650b2e92217715fe312e6fa7b90d82-Paper.pdf},
 year = {2020}
}

@article{hendrycks2021ethics,
  title={Aligning AI With Shared Human Values},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and Jerry Li and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2021},
url={https://openreview.net/pdf?id=dNy_RKzJacY}
}

@article{pruthi2022evaluating,
  title={Evaluating Explanations: How much do explanations from the teacher aid students?},
  author={Pruthi, Danish and Bansal, Rachit and Dhingra, Bhuwan and Soares, Livio Baldini and Collins, Michael and Lipton, Zachary C and Neubig, Graham and Cohen, William W},
  journal={Transactions of the Association for Computational Linguistics},
  year={2022},
}


@InProceedings{pmlr-v97-goyal19a,
  title = 	 {Counterfactual Visual Explanations},
  author =       {Goyal, Yash and Wu, Ziyan and Ernst, Jan and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
  url = 	 {https://proceedings.mlr.press/v97/goyal19a.html},
}

@InProceedings{Aodha_2018_CVPR,
author = {Mac Aodha, Oisin and Su, Shihan and Chen, Yuxin and Perona, Pietro and Yue, Yisong},
title = {Teaching Categories to Human Learners With Visual Explanations},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2018},
url={https://openaccess.thecvf.com/content_cvpr_2018/papers/Aodha_Teaching_Categories_to_CVPR_2018_paper.pdf}
}

@article{herman2017promise,
  title={The promise and peril of human evaluation for model interpretability},
  author={Herman, Bernease},
  journal={ArXiv},
url={https://arxiv.org/pdf/1711.07414.pdf},
  year={2017}
}

@article{lage2019evaluation,
  title={An evaluation of the human-interpretability of explanation},
  author={Lage, Isaac and Chen, Emily and He, Jeffrey and Narayanan, Menaka and Kim, Been and Gershman, Sam and Doshi-Velez, Finale},
  journal={ArXiv},
url={https://arxiv.org/pdf/1902.00006.pdf},
  year={2019}
}

@inproceedings{10.1145/2939672.2939778,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
url = {https://doi.org/10.1145/2939672.2939778},
booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
}

@inproceedings{gilpin2018explaining,
  title={Explaining explanations: An overview of interpretability of machine learning},
  author={Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
  booktitle={2018 IEEE 5th International Conference on data science and advanced analytics (DSAA)},
  year={2018},
  organization={IEEE},
url={https://ieeexplore.ieee.org/abstract/document/8631448}
}

@inproceedings{10.1145/3306618.3314229,
author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
title = {Faithful and Customizable Explanations of Black Box Models},
year = {2019},
url = {https://doi.org/10.1145/3306618.3314229},
booktitle = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
}

@book{harrington1985harvey,
  title={Harvey Friedman's research on the foundations of mathematics},
  author={Harrington, Leo A and Morley, Michael D and {\v{S}}cedrov, A and Simpson, Stephen G},
  year={1985},
url={https://books.google.com/books/about/Harvey_Friedman_s_Research_on_the_Founda.html?id=2plPRR4LDxIC}
}

@article{lyu2022towards,
  title={Towards Faithful Model Explanation in NLP: A Survey},
  author={Lyu, Qing and Apidianaki, Marianna and Callison-Burch, Chris},
journal={ArXiv},
url={https://arxiv.org/pdf/2209.11326.pdf},
year={2022}
}

@article{narang2020wt5,
  title={Wt5?! training text-to-text models to explain their predictions},
      author={Sharan Narang and Colin Raffel and Katherine Lee and Adam Roberts and Noah Fiedel and Karishma Malkan},
journal={ArXiv},
url={https://arxiv.org/pdf/2004.14546.pdf},
  year={2020}
}

@article{chen2022rev,
  title={REV: Information-Theoretic Evaluation of Free-Text Rationales},
  author={Chen, Hanjie and Brahman, Faeze and Ren, Xiang and Ji, Yangfeng and Choi, Yejin and Swayamdipta, Swabha},
journal={ArXiv},
url={https://arxiv.org/pdf/2210.04982.pdf},
year={2022}
}

@article{chan2022frame,
  title={FRAME: Evaluating Simulatability Metrics for Free-Text Rationales},
  author={Chan, Aaron and Nie, Shaoliang and Tan, Liang and Peng, Xiaochang and Firooz, Hamed and Sanjabi, Maziar and Ren, Xiang},
  journal={ArXiv},
url={https://arxiv.org/pdf/2207.00779.pdf},
  year={2022}
}

@article{sia2022logical,
  title={Logical Satisfiability of Counterfactuals for Faithful Explanations in NLI},
  author={Sia, Suzanna and Belyy, Anton and Almahairi, Amjad and Khabsa, Madian and Zettlemoyer, Luke and Mathias, Lambert},
journal={ArXiv},
url={https://arxiv.org/pdf/2205.12469.pdf},
year={2022}
}

@inproceedings{khattab2020colbert,
  title={Colbert: Efficient and effective passage search via contextualized late interaction over bert},
  author={Khattab, Omar and Zaharia, Matei},
  booktitle={Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval},
  pages={39--48},
  year={2020}
}

@misc{choi2024automatic,
  author       = {Choi, Dami and Huang, Vincent and Meng, Kevin and Johnson, Daniel D and Steinhardt, Jacob and Schwettmann, Sarah},
  title        = {Scaling Automatic Neuron Description},
  year         = {2024},
  month        = {October},
  day          = {23},
  howpublished = {\url{https://transluce.org/neuron-descriptions}}
}

@article{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{hewitt2025we,
  title={We Can't Understand AI Using our Existing Vocabulary},
  author={Hewitt, John and Geirhos, Robert and Kim, Been},
  journal={arXiv preprint arXiv:2502.07586},
  year={2025}
}

@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={1885--1894},
  year={2017},
  organization={PMLR}
}



@article{chen2024towards,
  title={Towards consistent natural-language explanations via explanation-consistency finetuning},
  author={Chen, Yanda and Singh, Chandan and Liu, Xiaodong and Zuo, Simiao and Yu, Bin and He, He and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2401.13986},
  year={2024}
}

@book{gentner2014mental,
  title={Mental models},
  author={Gentner, Dedre and Stevens, Albert L},
  year={2014},
url={https://books.google.com/books?id=G8iYAgAAQBAJ&lpg=PP1&ots=aNvUXUGG9t&dq=mental%20models%3B%20gentner&lr&pg=PP1#v=onepage&q=mental%20models;%20gentner&f=false}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020},
url={https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html}
}

@article{creswell2022faithful,
  title={Faithful reasoning using large language models},
  author={Creswell, Antonia and Shanahan, Murray},
  journal={ArXiv},
url={https://arxiv.org/pdf/2208.14271.pdf},
  year={2022}
}

@article{turpin2023language,
  title={Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting},
  author={Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel R},
journal={ArXiv},
url={https://arxiv.org/pdf/2305.04388.pdf},  year={2023}
}

@article{miller_2021, 
title={Contrastive explanation: a structural-model approach}, 
journal={The Knowledge Engineering Review},
author={Miller, Tim}, year={2021}, 
url={https://www.cambridge.org/core/journals/knowledge-engineering-review/article/abs/contrastive-explanation-a-structuralmodel-approach/69A2E32B160C2C7FB65BC88670D7AEA7}
}

@phdthesis{wu2022interactive,
  title={Interactive AI Model Debugging and Correction},
  author={Wu, Tongshuang},
  year={2022},
  school={University of Washington},
url={https://digital.lib.washington.edu/researchworks/handle/1773/49314}
}

@article{huang2022large,
  title={Large language models can self-improve},
  author={Huang, Jiaxin and Gu, Shixiang Shane and Hou, Le and Wu, Yuexin and Wang, Xuezhi and Yu, Hongkun and Han, Jiawei},
journal={ArXiv},
url={https://arxiv.org/pdf/2210.11610.pdf},  year={2022}
}

@article{weng2022large,
  title={Large language models are reasoners with self-verification},
  author={Weng, Yixuan and Zhu, Minjun and He, Shizhu and Liu, Kang and Zhao, Jun},
journal={ArXiv},
url={https://arxiv.org/pdf/2212.09561.pdf},
  year={2022}
}

@article{peng2023check,
  title={Check your facts and try again: Improving large language models with external knowledge and automated feedback},
  author={Peng, Baolin and Galley, Michel and He, Pengcheng and Cheng, Hao and Xie, Yujia and Hu, Yu and Huang, Qiuyuan and Liden, Lars and Yu, Zhou and Chen, Weizhu and others},
journal={ArXiv},
url={https://arxiv.org/pdf/2302.12813.pdf},  year={2023}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in Neural Information Processing Systems},
  year={2017},
url={https://papers.nips.cc/paper_files/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
journal={ArXiv},
url={https://arxiv.org/pdf/1707.06347.pdf},
  year={2017}
}

@inproceedings{chandrasekaran-etal-2018-explanations,
    title = "Do explanations make {VQA} models more predictable to a human?",
    author = "Chandrasekaran, Arjun  and
      Prabhu, Viraj  and
      Yadav, Deshraj  and
      Chattopadhyay, Prithvijit  and
      Parikh, Devi",
    booktitle = "Proceedings of Empirical Methods in Natural Language Processing",
    year = "2018",
    url = "https://aclanthology.org/D18-1128",
}

@article{geva-etal-2021-aristotle,
  title={Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies},
  author={Geva, Mor and Khashabi, Daniel and Segal, Elad and Khot, Tushar and Roth, Dan and Berant, Jonathan},
  journal={Transactions of the Association for Computational Linguistics},
  year={2021},
url={https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00370/100680/Did-Aristotle-Use-a-Laptop-A-Question-Answering}
}

@inproceedings{hase-bansal-2020-evaluating,
    title = "Evaluating Explainable {AI}: Which Algorithmic Explanations Help Users Predict Model Behavior?",
    author = "Hase, Peter  and
      Bansal, Mohit",
    booktitle = "Proceedings of the Association for Computational Linguistics",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.491",
}

@inproceedings{hase-etal-2020-leakage,
    title = "Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial Explanations of Their Behavior in Natural Language?",
    author = "Hase, Peter  and
      Zhang, Shiyue  and
      Xie, Harry  and
      Bansal, Mohit",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    year = "2020",
    url = "https://aclanthology.org/2020.findings-emnlp.390",
}

@inproceedings{jacovi-goldberg-2020-towards,
    title = "Towards Faithfully Interpretable {NLP} Systems: How Should We Define and Evaluate Faithfulness?",
    author = "Jacovi, Alon  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the Association for Computational Linguistics",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.386",
}

@inproceedings{jacovi-etal-2021-contrastive,
    title = "Contrastive Explanations for Model Interpretability",
    author = "Jacovi, Alon  and
      Swayamdipta, Swabha  and
      Ravfogel, Shauli  and
      Elazar, Yanai  and
      Choi, Yejin  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the Empirical Methods in Natural Language Processing",
    year = "2021",
    url = "https://aclanthology.org/2021.emnlp-main.120",
}

@inproceedings{kumar-talukdar-2020-nile,
    title = "{NILE} : Natural Language Inference with Faithful Natural Language Explanations",
    author = "Kumar, Sawan  and
      Talukdar, Partha",
    booktitle = "Proceedings of the Association for Computational Linguistics",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.771",
}

@inproceedings{li-etal-2020-evaluating,
    title = "Evaluating Explanation Methods for Neural Machine Translation",
    author = "Li, Jierui  and
      Liu, Lemao  and
      Li, Huayang  and
      Li, Guanlin  and
      Huang, Guoping  and
      Shi, Shuming",
    booktitle = "Proceedings of the Association for Computational Linguistics",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.35",
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the Association for Computational Linguistics",
    year = "2002",
    url = "https://aclanthology.org/P02-1040",
}

@inproceedings{ravfogel-etal-2020-null,
    title = "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection",
    author = "Ravfogel, Shauli  and
      Elazar, Yanai  and
      Gonen, Hila  and
      Twiton, Michael  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the Association for Computational Linguistics",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.647",
}

@inproceedings{wiegreffe-etal-2021-measuring,
    title = "{M}easuring Association Between Labels and Free-Text Rationales",
    author = "Wiegreffe, Sarah  and
      Marasovi{\'c}, Ana  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Empirical Methods in Natural Language Processing",
    year = "2021",
    url = "https://aclanthology.org/2021.emnlp-main.804",
}

@inproceedings{wu-mooney-2019-faithful,
    title = "Faithful Multimodal Explanation for Visual Question Answering",
    author = "Wu, Jialin  and
      Mooney, Raymond",
    booktitle = "Proceedings of the ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
    year = "2019",
    url = "https://aclanthology.org/W19-4812",
}

@inproceedings{wu-etal-2021-polyjuice,
    title = "Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models",
    author = "Wu, Tongshuang  and
      Ribeiro, Marco Tulio  and
      Heer, Jeffrey  and
      Weld, Daniel",
    booktitle = "Proceedings of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing",
    year = "2021",
    url = "https://aclanthology.org/2021.acl-long.523",
}

@inproceedings{ye-durrett-2022-explanations,
    title = "Can Explanations Be Useful for Calibrating Black Box Models?",
    author = "Ye, Xi  and
      Durrett, Greg",
    booktitle = "Proceedings of the Association for Computational Linguistics",
    month = may,
    year = "2022",
    url = "https://aclanthology.org/2022.acl-long.429",
}

@inproceedings{yin-neubig-2022-interpreting,
    title = "Interpreting Language Models with Contrastive Explanations",
    author = "Yin, Kayo  and
      Neubig, Graham",
    booktitle = "Proceedings of the Empirical Methods in Natural Language Processing",
    year = "2022",
    url = "https://aclanthology.org/2022.emnlp-main.14",
}

@inproceedings{zylberajch-etal-2021-hildif,
    title = "{HILDIF}: {I}nteractive Debugging of {NLI} Models Using Influence Functions",
    author = "Zylberajch, Hugo  and
      Lertvittayakumjorn, Piyawat  and
      Toni, Francesca",
    booktitle = "Proceedings of the First Workshop on Interactive Learning for Natural Language Processing",
    year = "2021",
    url = "https://aclanthology.org/2021.internlp-1.1",
}